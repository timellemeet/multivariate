{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "[-2 -2 -1 -2]\n",
      "[[ 1  1 -2  0]\n",
      " [ 0 -2 -2 -1]\n",
      " [ 0  0 -1  0]\n",
      " [-1 -2 -1  1]\n",
      " [ 1  0  1  0]]\n",
      "[1.91870459 1.95709201 0.67677567 1.37492433]\n",
      "[-0.04756076 -1.35692566 -1.09711342 -0.67016279]\n",
      "[[ 1.90329814  1.50542531  0.80261036 -0.57159806]\n",
      " [-0.24664611 -0.18440792  0.99091365  1.58875771]\n",
      " [ 0.20298406  1.42630122  0.85325438  0.15003145]\n",
      " [-0.92047723 -1.69937498 -0.17951784  0.53697878]\n",
      " [-1.77937368  0.11976502 -1.82261174 -0.92836946]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "size does not match the broadcast shape of the parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e7ac616d0ce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m# mu =  np.random.randint(-max_mu, max_mu, (1, n_vars))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m \u001b[0mskewnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[0mdiscrete\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'discrete'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[0mrndm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'random_state'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_args_rvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m         \u001b[0mcond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogical_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_argcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m_parse_args_rvs\u001b[1;34m(self, a, loc, scale, size)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m_argcheck_rvs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    847\u001b[0m                   for (bcdim, szdim) in zip(bcast_shape, size_)])\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 849\u001b[1;33m             raise ValueError(\"size does not match the broadcast shape of \"\n\u001b[0m\u001b[0;32m    850\u001b[0m                              \"the parameters.\")\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: size does not match the broadcast shape of the parameters."
     ]
    }
   ],
   "source": [
    "!activate PythonGPU\n",
    "import numpy as np\n",
    "from scipy.stats import skewnorm, skew\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, accuracy_score\n",
    "\n",
    "def simulate_data(classes, n_vars, n, max_mu, max_sigma, max_skew):\n",
    "    #The multivariate skew normal number generator\n",
    "    def rng(mu, sigma, skew, n=1):\n",
    "        k = len(mu)\n",
    "        if not (k == len(sigma) and k ==len(skew)): \n",
    "            raise Exception(\"Mu, Sigma and Skew should be same length\")\n",
    "\n",
    "        data = np.zeros((int(n),k))\n",
    "\n",
    "        for i in range(k):\n",
    "            data[:,i] = skewnorm.rvs(skew[i], loc=mu[i], scale=sigma[i], size=int(n)) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    if(np.sum(classes) != 1):\n",
    "        raise Exception(\"Classes dont sum up to 1\")\n",
    "        \n",
    "    n_classes = len(classes)\n",
    "#     sigma = np.random.randint(1,max_sigma,n_vars)\n",
    "#     skew = np.random.randint(-max_skew,max_skew,n_vars)\n",
    "#     mu =  np.random.randint(-max_mu, max_mu, (n_classes, n_vars))\n",
    "    \n",
    "    sigma = (max_sigma * np.random.rand(1,n_vars))[0]\n",
    "    skew = ((2 * max_skew  * np.random.rand(1, n_vars)) - max_skew)[0]\n",
    "    mu = (2 *  max_mu * np.random.rand(n_classes, n_vars)) - max_mu\n",
    "    \n",
    "    n_obs_class = np.round(np.dot(classes,n))\n",
    "    \n",
    "    data = np.zeros((int(np.sum(n_obs_class)),n_vars+1))\n",
    "    for i in range(n_classes):\n",
    "        #calculate indexes\n",
    "        start = int(np.sum(n_obs_class[0:i]))\n",
    "        end = int(np.sum(n_obs_class[0:i+1]))\n",
    "        \n",
    "        #set the data\n",
    "        data[start:end,0] = i\n",
    "        data[start:end,1:] = rng(mu[i,:], sigma, skew, n_obs_class[i])\n",
    "        \n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.99871232, 1.05954745, 0.12373237]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 *  3 * np.random.rand(1, 3)) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def classify_lda(X_train, X_test, y_train, y_test, priors, plot=False):\n",
    "    lda = LinearDiscriminantAnalysis(priors=priors)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    predictions = lda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"LDA Test accuracy \"+ str(accuracy))\n",
    "    print(predictions)\n",
    "\n",
    "    if plot:    \n",
    "        plt.xlabel('LD1')\n",
    "        plt.ylabel('LD2')\n",
    "        plt.scatter(\n",
    "            X_lda[:,0],\n",
    "            X_lda[:,1],\n",
    "            c=y_train,\n",
    "            cmap='Accent',\n",
    "        )\n",
    "        \n",
    "    return {\"method\": \"LDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": lda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadratic\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify_qda(X_train, X_test, y_train, y_test, priors):\n",
    "    qda = QuadraticDiscriminantAnalysis(priors=priors)\n",
    "    X_qda = qda.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = qda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"QDA Test accuracy \"+ str(accuracy))\n",
    "\n",
    "    return {\"method\": \"QDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": qda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classify_logit(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                             multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Logistic Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Logit\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def classify_knn(X_train, X_test, y_train, y_test, n_neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    predictions = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"KNN-\"+str(n_neighbors)+\" Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"KNN-\"+str(n_neighbors), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": knn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def classify_naivebayes(X_train, X_test, y_train, y_test, priors):\n",
    "    NB = GaussianNB(priors)\n",
    "    NB.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = NB.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"Naive Bayes Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Naive Bayes\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": NB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def classify_svm(X_train, X_test, y_train, y_test):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"SVM Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"SVM\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": svm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "def classify_neuralnet(X_train, X_test, y_train, y_test, n_vars, n_classes, depth=1, nodes=10, epochs=20):\n",
    "    inputs = keras.Input(shape=(n_vars,), name='obs')\n",
    "    x = layers.Dense(nodes, activation='relu')(inputs)\n",
    "    \n",
    "    if(depth>1):\n",
    "        for i in range(depth-1):\n",
    "            x = layers.Dense(nodes, activation='relu')(x)\n",
    "            \n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='Dataset')\n",
    "\n",
    "    display(model.summary())\n",
    "\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=64,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    print(predictions)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Neural Network Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Net \"+\"-\".join([str(nodes) for i in range(depth)])+ \" E\"+str(epochs), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test accuracy 0.5575757575757576\n",
      "[3. 0. 0. 1. 1. 3. 0. 1. 0. 3. 2. 1. 1. 0. 0. 3. 3. 1. 2. 3. 0. 2. 1. 2.\n",
      " 1. 3. 3. 2. 0. 3. 3. 1. 2. 3. 1. 1. 3. 1. 3. 1. 3. 0. 2. 2. 0. 1. 3. 2.\n",
      " 3. 1. 1. 3. 0. 3. 0. 3. 3. 2. 0. 1. 0. 0. 0. 1. 3. 0. 3. 3. 2. 0. 3. 1.\n",
      " 1. 1. 2. 3. 3. 0. 0. 1. 1. 3. 3. 3. 0. 0. 2. 3. 2. 0. 2. 3. 1. 3. 3. 0.\n",
      " 0. 3. 2. 3. 0. 0. 0. 3. 1. 2. 0. 0. 1. 2. 1. 3. 3. 0. 0. 1. 3. 1. 3. 1.\n",
      " 0. 1. 3. 3. 0. 1. 3. 1. 1. 0. 3. 0. 3. 2. 3. 1. 1. 0. 3. 1. 1. 1. 0. 2.\n",
      " 1. 0. 2. 1. 1. 1. 3. 1. 1. 3. 0. 3. 1. 0. 0. 3. 1. 0. 2. 2. 1.]\n",
      "QDA Test accuracy 0.5272727272727272\n",
      "Logistic Test accuracy 0.5636363636363636\n",
      "KNN-5 Test accuracy 0.4484848484848485\n",
      "KNN-10 Test accuracy 0.4909090909090909\n",
      "KNN-50 Test accuracy 0.5393939393939394\n",
      "KNN-100 Test accuracy 0.4727272727272727\n",
      "Naive Bayes Test accuracy 0.5333333333333333\n",
      "SVM Test accuracy 0.5636363636363636\n",
      "Model: \"Dataset\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "obs (InputLayer)             [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 268 samples, validate on 67 samples\n",
      "Epoch 1/25\n",
      "268/268 [==============================] - 1s 3ms/sample - loss: 1.4976 - accuracy: 0.1493 - val_loss: 1.4647 - val_accuracy: 0.1194\n",
      "Epoch 2/25\n",
      "268/268 [==============================] - 0s 217us/sample - loss: 1.4835 - accuracy: 0.1269 - val_loss: 1.4572 - val_accuracy: 0.1343\n",
      "Epoch 3/25\n",
      "268/268 [==============================] - 0s 202us/sample - loss: 1.4750 - accuracy: 0.1082 - val_loss: 1.4500 - val_accuracy: 0.1343\n",
      "Epoch 4/25\n",
      "268/268 [==============================] - 0s 216us/sample - loss: 1.4670 - accuracy: 0.1045 - val_loss: 1.4446 - val_accuracy: 0.1343\n",
      "Epoch 5/25\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 1.4602 - accuracy: 0.1157 - val_loss: 1.4387 - val_accuracy: 0.1343\n",
      "Epoch 6/25\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 1.4530 - accuracy: 0.1269 - val_loss: 1.4334 - val_accuracy: 0.1343\n",
      "Epoch 7/25\n",
      "268/268 [==============================] - 0s 190us/sample - loss: 1.4465 - accuracy: 0.1231 - val_loss: 1.4273 - val_accuracy: 0.1493\n",
      "Epoch 8/25\n",
      "268/268 [==============================] - 0s 186us/sample - loss: 1.4395 - accuracy: 0.1231 - val_loss: 1.4228 - val_accuracy: 0.1493\n",
      "Epoch 9/25\n",
      "268/268 [==============================] - 0s 205us/sample - loss: 1.4340 - accuracy: 0.1269 - val_loss: 1.4183 - val_accuracy: 0.1493\n",
      "Epoch 10/25\n",
      "268/268 [==============================] - 0s 164us/sample - loss: 1.4279 - accuracy: 0.1231 - val_loss: 1.4137 - val_accuracy: 0.1493\n",
      "Epoch 11/25\n",
      "268/268 [==============================] - 0s 160us/sample - loss: 1.4221 - accuracy: 0.1194 - val_loss: 1.4091 - val_accuracy: 0.1493\n",
      "Epoch 12/25\n",
      "268/268 [==============================] - 0s 179us/sample - loss: 1.4162 - accuracy: 0.1269 - val_loss: 1.4053 - val_accuracy: 0.1493\n",
      "Epoch 13/25\n",
      "268/268 [==============================] - 0s 172us/sample - loss: 1.4109 - accuracy: 0.1306 - val_loss: 1.4014 - val_accuracy: 0.1343\n",
      "Epoch 14/25\n",
      "268/268 [==============================] - 0s 179us/sample - loss: 1.4058 - accuracy: 0.1343 - val_loss: 1.3982 - val_accuracy: 0.1493\n",
      "Epoch 15/25\n",
      "268/268 [==============================] - 0s 179us/sample - loss: 1.4008 - accuracy: 0.1381 - val_loss: 1.3944 - val_accuracy: 0.1493\n",
      "Epoch 16/25\n",
      "268/268 [==============================] - 0s 205us/sample - loss: 1.3955 - accuracy: 0.1418 - val_loss: 1.3905 - val_accuracy: 0.1493\n",
      "Epoch 17/25\n",
      "268/268 [==============================] - 0s 186us/sample - loss: 1.3899 - accuracy: 0.1493 - val_loss: 1.3875 - val_accuracy: 0.1940\n",
      "Epoch 18/25\n",
      "268/268 [==============================] - 0s 220us/sample - loss: 1.3853 - accuracy: 0.1530 - val_loss: 1.3851 - val_accuracy: 0.1940\n",
      "Epoch 19/25\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 1.3813 - accuracy: 0.2388 - val_loss: 1.3829 - val_accuracy: 0.2388\n",
      "Epoch 20/25\n",
      "268/268 [==============================] - 0s 201us/sample - loss: 1.3771 - accuracy: 0.2500 - val_loss: 1.3800 - val_accuracy: 0.2537\n",
      "Epoch 21/25\n",
      "268/268 [==============================] - 0s 168us/sample - loss: 1.3722 - accuracy: 0.2500 - val_loss: 1.3773 - val_accuracy: 0.2836\n",
      "Epoch 22/25\n",
      "268/268 [==============================] - 0s 175us/sample - loss: 1.3679 - accuracy: 0.2575 - val_loss: 1.3755 - val_accuracy: 0.3134\n",
      "Epoch 23/25\n",
      "268/268 [==============================] - 0s 198us/sample - loss: 1.3644 - accuracy: 0.2799 - val_loss: 1.3729 - val_accuracy: 0.3284\n",
      "Epoch 24/25\n",
      "268/268 [==============================] - 0s 164us/sample - loss: 1.3599 - accuracy: 0.3172 - val_loss: 1.3708 - val_accuracy: 0.3284\n",
      "Epoch 25/25\n",
      "268/268 [==============================] - 0s 160us/sample - loss: 1.3558 - accuracy: 0.3321 - val_loss: 1.3690 - val_accuracy: 0.3284\n",
      "[1 2 0 1 1 2 0 1 0 1 1 1 1 2 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 2 0 0 1 1 0 0 1 1 1 2 1 0 1 1 0 1 1 1 3 1 0 0 0 1 1 0 1 0 0 2 0 1 1 1\n",
      " 1 1 1 0 2 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 1 1 0 3 0 1 1 0 0 0 2 1 1\n",
      " 0 1 2 0 2 1 1 1 1 2 1 1 1 2 2 1 1 1 0 1 0 1 1 1 1 1 2 1 1 2 1 0 1 2 0 1 0\n",
      " 1 1 1 2 1 1 0 1 1 0 0 1 1 0 1 1 1]\n",
      "Neural Network Test accuracy 0.36363636363636365\n",
      "Model: \"Dataset\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "obs (InputLayer)             [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30)                90        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 124       \n",
      "=================================================================\n",
      "Total params: 3,004\n",
      "Trainable params: 3,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 268 samples, validate on 67 samples\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 2s 6ms/sample - loss: 1.3663 - accuracy: 0.2425 - val_loss: 1.3404 - val_accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 0s 276us/sample - loss: 1.3373 - accuracy: 0.3022 - val_loss: 1.3247 - val_accuracy: 0.3433\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 0s 313us/sample - loss: 1.3177 - accuracy: 0.4104 - val_loss: 1.3121 - val_accuracy: 0.4328\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 0s 340us/sample - loss: 1.2998 - accuracy: 0.4664 - val_loss: 1.2954 - val_accuracy: 0.4478\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 0s 265us/sample - loss: 1.2826 - accuracy: 0.4851 - val_loss: 1.2736 - val_accuracy: 0.4627\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 0s 287us/sample - loss: 1.2595 - accuracy: 0.4963 - val_loss: 1.2544 - val_accuracy: 0.4776\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 0s 369us/sample - loss: 1.2335 - accuracy: 0.4963 - val_loss: 1.2362 - val_accuracy: 0.4776\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 0s 381us/sample - loss: 1.2118 - accuracy: 0.5075 - val_loss: 1.2247 - val_accuracy: 0.5075\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 0s 231us/sample - loss: 1.1902 - accuracy: 0.4925 - val_loss: 1.2068 - val_accuracy: 0.4925\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 0s 216us/sample - loss: 1.1675 - accuracy: 0.5037 - val_loss: 1.1936 - val_accuracy: 0.5075\n",
      "[3 2 0 1 1 3 0 1 0 3 3 1 1 0 0 3 3 1 1 1 0 0 1 3 1 3 3 1 0 3 3 1 1 3 1 1 3\n",
      " 1 3 1 3 0 1 3 0 1 3 0 3 1 1 3 0 1 0 3 3 3 0 1 0 0 0 1 3 0 3 3 0 0 0 1 1 1\n",
      " 1 3 3 0 0 1 1 3 1 3 0 0 3 3 0 0 1 0 1 3 3 0 0 3 3 3 0 0 0 3 1 0 0 0 1 1 1\n",
      " 3 3 0 0 1 3 1 3 1 0 1 3 3 1 1 3 1 1 0 3 0 3 1 3 1 1 0 3 1 1 1 0 3 1 0 0 1\n",
      " 1 1 3 1 1 3 0 1 1 0 0 3 1 0 1 3 1]\n",
      "Neural Network Test accuracy 0.5515151515151515\n",
      "Model: \"Dataset\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "obs (InputLayer)             [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 8,004\n",
      "Trainable params: 8,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 268 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "268/268 [==============================] - 2s 9ms/sample - loss: 1.3657 - accuracy: 0.3060 - val_loss: 1.3457 - val_accuracy: 0.3731\n",
      "Epoch 2/50\n",
      "268/268 [==============================] - 0s 463us/sample - loss: 1.3032 - accuracy: 0.4739 - val_loss: 1.2866 - val_accuracy: 0.4776\n",
      "Epoch 3/50\n",
      "268/268 [==============================] - 0s 246us/sample - loss: 1.2474 - accuracy: 0.4925 - val_loss: 1.2585 - val_accuracy: 0.4179\n",
      "Epoch 4/50\n",
      "268/268 [==============================] - 0s 231us/sample - loss: 1.2086 - accuracy: 0.4963 - val_loss: 1.2231 - val_accuracy: 0.4478\n",
      "Epoch 5/50\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 1.1697 - accuracy: 0.4925 - val_loss: 1.1800 - val_accuracy: 0.4925\n",
      "Epoch 6/50\n",
      "268/268 [==============================] - 0s 358us/sample - loss: 1.1394 - accuracy: 0.5112 - val_loss: 1.1637 - val_accuracy: 0.5373\n",
      "Epoch 7/50\n",
      "268/268 [==============================] - 0s 325us/sample - loss: 1.1122 - accuracy: 0.5037 - val_loss: 1.1738 - val_accuracy: 0.5075\n",
      "Epoch 8/50\n",
      "268/268 [==============================] - 0s 205us/sample - loss: 1.0942 - accuracy: 0.5037 - val_loss: 1.1543 - val_accuracy: 0.5373\n",
      "Epoch 9/50\n",
      "268/268 [==============================] - 0s 168us/sample - loss: 1.0802 - accuracy: 0.5187 - val_loss: 1.1465 - val_accuracy: 0.5224\n",
      "Epoch 10/50\n",
      "268/268 [==============================] - 0s 179us/sample - loss: 1.0774 - accuracy: 0.5075 - val_loss: 1.1197 - val_accuracy: 0.5224\n",
      "Epoch 11/50\n",
      "268/268 [==============================] - 0s 190us/sample - loss: 1.0574 - accuracy: 0.5187 - val_loss: 1.0965 - val_accuracy: 0.5224\n",
      "Epoch 12/50\n",
      "268/268 [==============================] - 0s 198us/sample - loss: 1.0512 - accuracy: 0.5187 - val_loss: 1.1285 - val_accuracy: 0.5373\n",
      "Epoch 13/50\n",
      "268/268 [==============================] - 0s 183us/sample - loss: 1.0397 - accuracy: 0.5224 - val_loss: 1.1013 - val_accuracy: 0.5522\n",
      "Epoch 14/50\n",
      "268/268 [==============================] - 0s 172us/sample - loss: 1.0322 - accuracy: 0.5149 - val_loss: 1.0782 - val_accuracy: 0.5373\n",
      "Epoch 15/50\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 1.0291 - accuracy: 0.5149 - val_loss: 1.1165 - val_accuracy: 0.5224\n",
      "Epoch 16/50\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 1.0210 - accuracy: 0.5299 - val_loss: 1.1089 - val_accuracy: 0.5224\n",
      "Epoch 17/50\n",
      "268/268 [==============================] - 0s 205us/sample - loss: 1.0195 - accuracy: 0.5187 - val_loss: 1.0756 - val_accuracy: 0.5373\n",
      "Epoch 18/50\n",
      "268/268 [==============================] - 0s 328us/sample - loss: 1.0116 - accuracy: 0.5410 - val_loss: 1.0942 - val_accuracy: 0.5672\n",
      "Epoch 19/50\n",
      "268/268 [==============================] - 0s 295us/sample - loss: 1.0120 - accuracy: 0.5187 - val_loss: 1.0911 - val_accuracy: 0.5522\n",
      "Epoch 20/50\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.9967 - accuracy: 0.5373 - val_loss: 1.0543 - val_accuracy: 0.5522\n",
      "Epoch 21/50\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.9945 - accuracy: 0.5448 - val_loss: 1.0814 - val_accuracy: 0.5224\n",
      "Epoch 22/50\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.9939 - accuracy: 0.5634 - val_loss: 1.0606 - val_accuracy: 0.5672\n",
      "Epoch 23/50\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 0.9862 - accuracy: 0.5448 - val_loss: 1.1041 - val_accuracy: 0.5672\n",
      "Epoch 24/50\n",
      "268/268 [==============================] - 0s 187us/sample - loss: 0.9875 - accuracy: 0.5448 - val_loss: 1.0814 - val_accuracy: 0.5224\n",
      "Epoch 25/50\n",
      "268/268 [==============================] - 0s 250us/sample - loss: 0.9886 - accuracy: 0.5373 - val_loss: 1.0521 - val_accuracy: 0.5522\n",
      "Epoch 26/50\n",
      "268/268 [==============================] - 0s 276us/sample - loss: 0.9789 - accuracy: 0.5672 - val_loss: 1.0477 - val_accuracy: 0.5672\n",
      "Epoch 27/50\n",
      "268/268 [==============================] - 0s 250us/sample - loss: 0.9773 - accuracy: 0.5634 - val_loss: 1.0575 - val_accuracy: 0.5821\n",
      "Epoch 28/50\n",
      "268/268 [==============================] - 0s 205us/sample - loss: 0.9758 - accuracy: 0.5597 - val_loss: 1.0797 - val_accuracy: 0.5522\n",
      "Epoch 29/50\n",
      "268/268 [==============================] - 0s 183us/sample - loss: 0.9748 - accuracy: 0.5299 - val_loss: 1.0666 - val_accuracy: 0.5672\n",
      "Epoch 30/50\n",
      "268/268 [==============================] - 0s 187us/sample - loss: 0.9671 - accuracy: 0.5597 - val_loss: 1.0809 - val_accuracy: 0.5672\n",
      "Epoch 31/50\n",
      "268/268 [==============================] - 0s 168us/sample - loss: 0.9692 - accuracy: 0.5560 - val_loss: 1.0802 - val_accuracy: 0.5821\n",
      "Epoch 32/50\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.9621 - accuracy: 0.5485 - val_loss: 1.0700 - val_accuracy: 0.5821\n",
      "Epoch 33/50\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 0.9601 - accuracy: 0.5709 - val_loss: 1.0644 - val_accuracy: 0.5224\n",
      "Epoch 34/50\n",
      "268/268 [==============================] - 0s 198us/sample - loss: 0.9643 - accuracy: 0.5821 - val_loss: 1.0829 - val_accuracy: 0.5821\n",
      "Epoch 35/50\n",
      "268/268 [==============================] - 0s 183us/sample - loss: 0.9625 - accuracy: 0.5373 - val_loss: 1.0831 - val_accuracy: 0.5672\n",
      "Epoch 36/50\n",
      "268/268 [==============================] - 0s 164us/sample - loss: 0.9598 - accuracy: 0.5485 - val_loss: 1.0459 - val_accuracy: 0.5672\n",
      "Epoch 37/50\n",
      "268/268 [==============================] - 0s 172us/sample - loss: 0.9580 - accuracy: 0.5746 - val_loss: 1.0389 - val_accuracy: 0.5075\n",
      "Epoch 38/50\n",
      "268/268 [==============================] - 0s 190us/sample - loss: 0.9588 - accuracy: 0.5485 - val_loss: 1.0379 - val_accuracy: 0.5672\n",
      "Epoch 39/50\n",
      "268/268 [==============================] - 0s 190us/sample - loss: 0.9597 - accuracy: 0.5672 - val_loss: 1.0321 - val_accuracy: 0.5672\n",
      "Epoch 40/50\n",
      "268/268 [==============================] - 0s 187us/sample - loss: 0.9556 - accuracy: 0.5784 - val_loss: 1.0528 - val_accuracy: 0.5075\n",
      "Epoch 41/50\n",
      "268/268 [==============================] - 0s 175us/sample - loss: 0.9606 - accuracy: 0.5709 - val_loss: 1.0600 - val_accuracy: 0.5522\n",
      "Epoch 42/50\n",
      "268/268 [==============================] - 0s 179us/sample - loss: 0.9586 - accuracy: 0.5709 - val_loss: 1.0462 - val_accuracy: 0.5522\n",
      "Epoch 43/50\n",
      "268/268 [==============================] - 0s 198us/sample - loss: 0.9495 - accuracy: 0.5672 - val_loss: 1.0375 - val_accuracy: 0.5522\n",
      "Epoch 44/50\n",
      "268/268 [==============================] - 0s 175us/sample - loss: 0.9560 - accuracy: 0.5672 - val_loss: 1.0509 - val_accuracy: 0.5821\n",
      "Epoch 45/50\n",
      "268/268 [==============================] - 0s 179us/sample - loss: 0.9482 - accuracy: 0.5821 - val_loss: 1.0732 - val_accuracy: 0.5821\n",
      "Epoch 46/50\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 0.9506 - accuracy: 0.5858 - val_loss: 1.0558 - val_accuracy: 0.5821\n",
      "Epoch 47/50\n",
      "268/268 [==============================] - 0s 198us/sample - loss: 0.9472 - accuracy: 0.5746 - val_loss: 1.0348 - val_accuracy: 0.5672\n",
      "Epoch 48/50\n",
      "268/268 [==============================] - 0s 168us/sample - loss: 0.9467 - accuracy: 0.5858 - val_loss: 1.0564 - val_accuracy: 0.5373\n",
      "Epoch 49/50\n",
      "268/268 [==============================] - 0s 187us/sample - loss: 0.9444 - accuracy: 0.5746 - val_loss: 1.0522 - val_accuracy: 0.5522\n",
      "Epoch 50/50\n",
      "268/268 [==============================] - 0s 276us/sample - loss: 0.9510 - accuracy: 0.5672 - val_loss: 1.0484 - val_accuracy: 0.5224\n",
      "[3 2 0 2 1 3 3 1 0 3 2 2 1 2 0 3 3 1 2 3 0 2 1 2 1 3 3 2 0 3 3 2 2 3 1 1 3\n",
      " 2 3 1 3 0 2 2 0 1 3 2 2 1 1 3 2 3 0 3 3 2 0 2 3 0 0 1 3 0 3 3 3 2 3 3 1 1\n",
      " 2 3 3 0 2 1 1 3 3 3 0 0 2 2 2 0 2 3 2 3 3 0 0 3 2 3 0 0 0 3 1 2 0 0 2 2 1\n",
      " 3 3 2 0 2 3 1 3 3 0 2 3 3 2 1 3 1 1 0 3 0 3 2 3 1 1 0 3 1 1 2 0 2 1 0 2 1\n",
      " 1 1 3 1 2 3 0 3 1 2 0 3 1 0 2 2 1]\n",
      "Neural Network Test accuracy 0.5393939393939394\n",
      "Results after config 1 of 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >method</th>        <th class=\"col_heading level0 col1\" >accuracy</th>        <th class=\"col_heading level0 col2\" >predictions</th>        <th class=\"col_heading level0 col3\" >model</th>        <th class=\"col_heading level0 col4\" >config</th>        <th class=\"col_heading level0 col5\" >classes</th>        <th class=\"col_heading level0 col6\" >n_vars</th>        <th class=\"col_heading level0 col7\" >n</th>        <th class=\"col_heading level0 col8\" >max_mu</th>        <th class=\"col_heading level0 col9\" >max_sigma</th>        <th class=\"col_heading level0 col10\" >max_skew</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col0\" class=\"data row0 col0\" >Logit</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col1\" class=\"data row0 col1\" >56.364%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col2\" class=\"data row0 col2\" >[3. 0. 0. 1. 1. 3. 0. 1. 0. 3. 2. 1. 1. 0. 0. 3. 3. 1. 2. 3. 0. 2. 1. 2.\n",
       " 1. 3. 3. 2. 0. 3. 3. 1. 1. 3. 1. 1. 3. 1. 3. 1. 3. 0. 1. 2. 0. 1. 3. 2.\n",
       " 3. 1. 1. 3. 0. 3. 0. 3. 3. 2. 0. 1. 0. 0. 0. 1. 3. 0. 3. 3. 0. 0. 3. 1.\n",
       " 1. 1. 2. 3. 3. 0. 0. 1. 1. 3. 3. 3. 0. 0. 2. 3. 2. 0. 2. 3. 1. 3. 3. 0.\n",
       " 0. 3. 2. 3. 0. 0. 0. 3. 1. 0. 0. 0. 1. 2. 1. 3. 3. 0. 0. 1. 3. 1. 3. 1.\n",
       " 0. 1. 3. 3. 0. 1. 3. 1. 1. 0. 3. 0. 3. 2. 3. 1. 1. 0. 3. 1. 1. 1. 0. 2.\n",
       " 1. 0. 2. 1. 1. 1. 3. 1. 1. 3. 0. 3. 1. 0. 0. 3. 1. 0. 2. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col3\" class=\"data row0 col3\" >LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col5\" class=\"data row0 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col6\" class=\"data row0 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col7\" class=\"data row0 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col8\" class=\"data row0 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col9\" class=\"data row0 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row0_col10\" class=\"data row0 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row1\" class=\"row_heading level0 row1\" >8</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col0\" class=\"data row1 col0\" >SVM</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col1\" class=\"data row1 col1\" >56.364%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col2\" class=\"data row1 col2\" >[3. 0. 0. 1. 1. 3. 0. 1. 0. 3. 3. 1. 1. 0. 0. 3. 3. 1. 0. 3. 0. 0. 1. 3.\n",
       " 1. 3. 3. 1. 0. 3. 3. 1. 1. 3. 1. 1. 3. 1. 3. 1. 3. 0. 1. 3. 0. 1. 3. 0.\n",
       " 3. 1. 1. 3. 0. 3. 0. 3. 3. 3. 0. 1. 0. 0. 0. 1. 3. 0. 3. 3. 0. 0. 3. 1.\n",
       " 1. 1. 1. 3. 3. 0. 0. 1. 1. 3. 3. 3. 0. 0. 2. 3. 0. 0. 1. 3. 1. 3. 3. 0.\n",
       " 0. 3. 3. 3. 0. 0. 0. 3. 1. 0. 0. 0. 1. 1. 1. 3. 3. 0. 0. 1. 3. 1. 3. 3.\n",
       " 0. 1. 3. 3. 0. 1. 3. 1. 1. 0. 3. 0. 3. 1. 3. 1. 1. 0. 3. 1. 1. 1. 0. 1.\n",
       " 1. 0. 0. 1. 1. 1. 3. 1. 1. 3. 0. 3. 1. 0. 0. 3. 1. 0. 1. 3. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col3\" class=\"data row1 col3\" >LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col5\" class=\"data row1 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col6\" class=\"data row1 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col7\" class=\"data row1 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col8\" class=\"data row1 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col9\" class=\"data row1 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row1_col10\" class=\"data row1 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col0\" class=\"data row2 col0\" >LDA</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col1\" class=\"data row2 col1\" >55.758%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col2\" class=\"data row2 col2\" >[3. 0. 0. 1. 1. 3. 0. 1. 0. 3. 2. 1. 1. 0. 0. 3. 3. 1. 2. 3. 0. 2. 1. 2.\n",
       " 1. 3. 3. 2. 0. 3. 3. 1. 2. 3. 1. 1. 3. 1. 3. 1. 3. 0. 2. 2. 0. 1. 3. 2.\n",
       " 3. 1. 1. 3. 0. 3. 0. 3. 3. 2. 0. 1. 0. 0. 0. 1. 3. 0. 3. 3. 2. 0. 3. 1.\n",
       " 1. 1. 2. 3. 3. 0. 0. 1. 1. 3. 3. 3. 0. 0. 2. 3. 2. 0. 2. 3. 1. 3. 3. 0.\n",
       " 0. 3. 2. 3. 0. 0. 0. 3. 1. 2. 0. 0. 1. 2. 1. 3. 3. 0. 0. 1. 3. 1. 3. 1.\n",
       " 0. 1. 3. 3. 0. 1. 3. 1. 1. 0. 3. 0. 3. 2. 3. 1. 1. 0. 3. 1. 1. 1. 0. 2.\n",
       " 1. 0. 2. 1. 1. 1. 3. 1. 1. 3. 0. 3. 1. 0. 0. 3. 1. 0. 2. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col3\" class=\"data row2 col3\" >LinearDiscriminantAnalysis(n_components=None, priors=[0.25, 0.25, 0.25, 0.25],\n",
       "              shrinkage=None, solver='svd', store_covariance=False,\n",
       "              tol=0.0001)</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col5\" class=\"data row2 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col6\" class=\"data row2 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col7\" class=\"data row2 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col8\" class=\"data row2 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col9\" class=\"data row2 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row2_col10\" class=\"data row2 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row3\" class=\"row_heading level0 row3\" >10</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col0\" class=\"data row3 col0\" >Net 30-30-30-30 E10</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col1\" class=\"data row3 col1\" >55.152%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col2\" class=\"data row3 col2\" >[3 2 0 1 1 3 0 1 0 3 3 1 1 0 0 3 3 1 1 1 0 0 1 3 1 3 3 1 0 3 3 1 1 3 1 1 3\n",
       " 1 3 1 3 0 1 3 0 1 3 0 3 1 1 3 0 1 0 3 3 3 0 1 0 0 0 1 3 0 3 3 0 0 0 1 1 1\n",
       " 1 3 3 0 0 1 1 3 1 3 0 0 3 3 0 0 1 0 1 3 3 0 0 3 3 3 0 0 0 3 1 0 0 0 1 1 1\n",
       " 3 3 0 0 1 3 1 3 1 0 1 3 3 1 1 3 1 1 0 3 0 3 1 3 1 1 0 3 1 1 1 0 3 1 0 0 1\n",
       " 1 1 3 1 1 3 0 1 1 0 0 3 1 0 1 3 1]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col3\" class=\"data row3 col3\" ><tensorflow.python.keras.engine.training.Model object at 0x000002620C142940></td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col4\" class=\"data row3 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col5\" class=\"data row3 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col6\" class=\"data row3 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col7\" class=\"data row3 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col8\" class=\"data row3 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col9\" class=\"data row3 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row3_col10\" class=\"data row3 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col0\" class=\"data row4 col0\" >KNN-50</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col1\" class=\"data row4 col1\" >53.939%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col2\" class=\"data row4 col2\" >[3. 2. 0. 1. 1. 0. 0. 1. 0. 2. 2. 2. 1. 0. 0. 1. 3. 1. 2. 1. 0. 0. 2. 2.\n",
       " 1. 2. 3. 2. 0. 3. 1. 1. 2. 3. 1. 1. 3. 2. 3. 1. 3. 0. 2. 2. 0. 1. 3. 2.\n",
       " 2. 1. 1. 3. 0. 1. 0. 3. 3. 2. 0. 1. 0. 0. 0. 1. 2. 0. 3. 3. 0. 0. 0. 1.\n",
       " 1. 1. 2. 3. 3. 0. 0. 1. 1. 3. 1. 3. 0. 0. 2. 2. 2. 0. 2. 0. 2. 3. 3. 0.\n",
       " 0. 3. 2. 2. 0. 0. 0. 3. 1. 0. 0. 0. 1. 2. 1. 3. 3. 0. 0. 2. 3. 1. 3. 2.\n",
       " 0. 1. 3. 1. 2. 1. 3. 1. 1. 0. 3. 0. 3. 2. 2. 1. 1. 0. 2. 1. 2. 2. 0. 2.\n",
       " 1. 0. 0. 1. 1. 1. 3. 2. 2. 3. 0. 1. 1. 0. 0. 3. 1. 0. 2. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col3\" class=\"data row4 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=50, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col5\" class=\"data row4 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col6\" class=\"data row4 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col7\" class=\"data row4 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col8\" class=\"data row4 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col9\" class=\"data row4 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row4_col10\" class=\"data row4 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row5\" class=\"row_heading level0 row5\" >11</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col0\" class=\"data row5 col0\" >Net 50-50-50-50 E50</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col1\" class=\"data row5 col1\" >53.939%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col2\" class=\"data row5 col2\" >[3 2 0 2 1 3 3 1 0 3 2 2 1 2 0 3 3 1 2 3 0 2 1 2 1 3 3 2 0 3 3 2 2 3 1 1 3\n",
       " 2 3 1 3 0 2 2 0 1 3 2 2 1 1 3 2 3 0 3 3 2 0 2 3 0 0 1 3 0 3 3 3 2 3 3 1 1\n",
       " 2 3 3 0 2 1 1 3 3 3 0 0 2 2 2 0 2 3 2 3 3 0 0 3 2 3 0 0 0 3 1 2 0 0 2 2 1\n",
       " 3 3 2 0 2 3 1 3 3 0 2 3 3 2 1 3 1 1 0 3 0 3 2 3 1 1 0 3 1 1 2 0 2 1 0 2 1\n",
       " 1 1 3 1 2 3 0 3 1 2 0 3 1 0 2 2 1]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col3\" class=\"data row5 col3\" ><tensorflow.python.keras.engine.training.Model object at 0x0000026207979A90></td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col4\" class=\"data row5 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col5\" class=\"data row5 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col6\" class=\"data row5 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col7\" class=\"data row5 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col8\" class=\"data row5 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col9\" class=\"data row5 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row5_col10\" class=\"data row5 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col0\" class=\"data row6 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col1\" class=\"data row6 col1\" >53.333%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col2\" class=\"data row6 col2\" >[3. 0. 0. 2. 1. 2. 0. 3. 0. 3. 2. 1. 1. 2. 0. 3. 3. 1. 2. 3. 0. 2. 1. 2.\n",
       " 1. 3. 3. 2. 0. 3. 3. 1. 2. 3. 1. 1. 3. 2. 3. 1. 3. 0. 2. 2. 0. 1. 3. 2.\n",
       " 2. 1. 1. 3. 2. 3. 0. 3. 3. 2. 0. 2. 0. 0. 0. 1. 3. 0. 3. 3. 2. 0. 3. 3.\n",
       " 1. 1. 2. 3. 3. 0. 0. 1. 1. 3. 3. 3. 0. 0. 2. 2. 2. 0. 2. 3. 2. 3. 3. 0.\n",
       " 0. 3. 2. 3. 0. 0. 0. 3. 1. 2. 0. 0. 2. 2. 1. 3. 3. 0. 2. 2. 3. 1. 3. 1.\n",
       " 0. 2. 3. 3. 0. 1. 3. 1. 1. 0. 3. 0. 3. 2. 2. 1. 1. 0. 3. 1. 1. 2. 0. 2.\n",
       " 1. 0. 2. 1. 1. 1. 3. 1. 2. 3. 0. 3. 1. 0. 0. 3. 1. 0. 2. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col3\" class=\"data row6 col3\" >GaussianNB(priors=[0.25, 0.25, 0.25, 0.25], var_smoothing=1e-09)</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col4\" class=\"data row6 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col5\" class=\"data row6 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col6\" class=\"data row6 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col7\" class=\"data row6 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col8\" class=\"data row6 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col9\" class=\"data row6 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row6_col10\" class=\"data row6 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row7\" class=\"row_heading level0 row7\" >1</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col0\" class=\"data row7 col0\" >QDA</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col1\" class=\"data row7 col1\" >52.727%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col2\" class=\"data row7 col2\" >[3. 0. 0. 2. 1. 2. 0. 3. 0. 3. 2. 1. 1. 2. 0. 3. 3. 1. 2. 3. 0. 2. 1. 2.\n",
       " 1. 3. 3. 2. 0. 3. 3. 1. 2. 3. 1. 1. 3. 2. 3. 1. 3. 0. 2. 2. 0. 1. 3. 2.\n",
       " 2. 1. 1. 3. 2. 3. 0. 3. 3. 2. 0. 2. 0. 0. 0. 1. 3. 0. 3. 3. 2. 0. 3. 1.\n",
       " 1. 1. 2. 3. 3. 0. 0. 1. 1. 3. 3. 3. 0. 0. 2. 2. 2. 0. 2. 3. 2. 3. 3. 0.\n",
       " 0. 3. 2. 3. 0. 0. 0. 3. 1. 2. 0. 0. 2. 2. 1. 3. 3. 0. 2. 2. 3. 1. 3. 1.\n",
       " 0. 2. 3. 3. 0. 1. 3. 1. 1. 0. 3. 0. 3. 2. 2. 1. 1. 0. 3. 1. 1. 2. 0. 2.\n",
       " 1. 0. 2. 1. 1. 1. 3. 1. 2. 3. 0. 3. 1. 2. 0. 3. 1. 0. 2. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col3\" class=\"data row7 col3\" >QuadraticDiscriminantAnalysis(priors=array([0.25, 0.25, 0.25, 0.25]),\n",
       "               reg_param=0.0, store_covariance=False,\n",
       "               store_covariances=None, tol=0.0001)</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col4\" class=\"data row7 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col5\" class=\"data row7 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col6\" class=\"data row7 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col7\" class=\"data row7 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col8\" class=\"data row7 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col9\" class=\"data row7 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row7_col10\" class=\"data row7 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row8\" class=\"row_heading level0 row8\" >4</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col0\" class=\"data row8 col0\" >KNN-10</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col1\" class=\"data row8 col1\" >49.091%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col2\" class=\"data row8 col2\" >[2. 0. 0. 2. 1. 1. 3. 1. 0. 2. 1. 1. 1. 0. 0. 3. 3. 1. 1. 3. 0. 1. 1. 2.\n",
       " 1. 2. 3. 1. 0. 3. 1. 2. 2. 3. 1. 1. 3. 2. 3. 1. 3. 0. 2. 0. 0. 1. 1. 1.\n",
       " 2. 2. 3. 3. 0. 3. 0. 3. 3. 2. 0. 2. 0. 0. 0. 2. 2. 0. 3. 3. 3. 0. 3. 3.\n",
       " 1. 2. 0. 3. 3. 0. 0. 1. 1. 3. 3. 3. 0. 2. 2. 2. 2. 0. 2. 3. 2. 2. 3. 0.\n",
       " 0. 3. 2. 2. 0. 1. 0. 3. 1. 1. 0. 1. 1. 2. 1. 3. 3. 0. 0. 1. 3. 1. 2. 1.\n",
       " 0. 2. 3. 1. 2. 1. 3. 2. 1. 0. 3. 1. 3. 0. 3. 2. 2. 1. 2. 1. 1. 2. 0. 0.\n",
       " 1. 0. 0. 1. 1. 1. 1. 1. 1. 3. 0. 3. 1. 3. 0. 3. 1. 0. 0. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col3\" class=\"data row8 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col4\" class=\"data row8 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col5\" class=\"data row8 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col6\" class=\"data row8 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col7\" class=\"data row8 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col8\" class=\"data row8 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col9\" class=\"data row8 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row8_col10\" class=\"data row8 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row9\" class=\"row_heading level0 row9\" >6</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col0\" class=\"data row9 col0\" >KNN-100</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col1\" class=\"data row9 col1\" >47.273%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col2\" class=\"data row9 col2\" >[2. 2. 0. 2. 1. 0. 0. 1. 0. 2. 2. 2. 1. 2. 0. 1. 3. 1. 2. 1. 0. 2. 1. 2.\n",
       " 1. 2. 3. 2. 0. 3. 1. 2. 2. 3. 1. 1. 3. 2. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2.\n",
       " 2. 1. 1. 0. 0. 1. 0. 3. 3. 2. 0. 2. 0. 0. 0. 1. 2. 0. 3. 0. 0. 0. 0. 1.\n",
       " 1. 1. 2. 1. 3. 0. 2. 1. 1. 3. 1. 3. 0. 0. 2. 2. 2. 0. 2. 0. 2. 3. 3. 0.\n",
       " 0. 0. 2. 3. 0. 0. 0. 3. 1. 0. 0. 0. 2. 2. 1. 0. 3. 0. 0. 1. 3. 1. 3. 1.\n",
       " 0. 2. 3. 1. 2. 1. 3. 1. 1. 0. 1. 0. 3. 2. 2. 1. 1. 0. 3. 1. 2. 2. 0. 2.\n",
       " 1. 0. 2. 1. 1. 1. 3. 1. 2. 3. 0. 1. 1. 0. 0. 2. 1. 0. 2. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col3\" class=\"data row9 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=100, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col4\" class=\"data row9 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col5\" class=\"data row9 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col6\" class=\"data row9 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col7\" class=\"data row9 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col8\" class=\"data row9 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col9\" class=\"data row9 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row9_col10\" class=\"data row9 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row10\" class=\"row_heading level0 row10\" >3</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col0\" class=\"data row10 col0\" >KNN-5</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col1\" class=\"data row10 col1\" >44.848%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col2\" class=\"data row10 col2\" >[2. 1. 0. 2. 1. 3. 1. 1. 0. 2. 1. 1. 1. 0. 0. 3. 3. 1. 0. 3. 0. 0. 1. 1.\n",
       " 1. 1. 3. 1. 0. 3. 1. 2. 2. 3. 1. 1. 3. 2. 3. 2. 3. 0. 2. 0. 0. 1. 1. 0.\n",
       " 1. 2. 1. 3. 0. 3. 0. 3. 3. 2. 0. 2. 0. 0. 0. 1. 2. 0. 3. 3. 3. 0. 3. 1.\n",
       " 1. 1. 0. 3. 0. 1. 1. 1. 1. 3. 3. 3. 0. 0. 1. 2. 1. 0. 2. 3. 2. 3. 3. 0.\n",
       " 0. 3. 0. 2. 0. 1. 0. 3. 1. 1. 0. 0. 1. 1. 1. 3. 3. 0. 2. 1. 3. 1. 2. 1.\n",
       " 0. 2. 3. 0. 1. 1. 3. 1. 1. 0. 3. 0. 3. 0. 3. 2. 2. 0. 1. 1. 1. 2. 0. 0.\n",
       " 2. 0. 0. 1. 1. 0. 1. 1. 2. 3. 0. 3. 2. 1. 1. 1. 1. 0. 0. 2. 1.]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col3\" class=\"data row10 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col4\" class=\"data row10 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col5\" class=\"data row10 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col6\" class=\"data row10 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col7\" class=\"data row10 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col8\" class=\"data row10 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col9\" class=\"data row10 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row10_col10\" class=\"data row10 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098level0_row11\" class=\"row_heading level0 row11\" >9</th>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col0\" class=\"data row11 col0\" >Net 4 E25</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col1\" class=\"data row11 col1\" >36.364%</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col2\" class=\"data row11 col2\" >[1 2 0 1 1 2 0 1 0 1 1 1 1 2 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
       " 1 1 2 0 0 1 1 0 0 1 1 1 2 1 0 1 1 0 1 1 1 3 1 0 0 0 1 1 0 1 0 0 2 0 1 1 1\n",
       " 1 1 1 0 2 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 1 1 0 3 0 1 1 0 0 0 2 1 1\n",
       " 0 1 2 0 2 1 1 1 1 2 1 1 1 2 2 1 1 1 0 1 0 1 1 1 1 1 2 1 1 2 1 0 1 2 0 1 0\n",
       " 1 1 1 2 1 1 0 1 1 0 0 1 1 0 1 1 1]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col3\" class=\"data row11 col3\" ><tensorflow.python.keras.engine.training.Model object at 0x000002620B716898></td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col4\" class=\"data row11 col4\" >1</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col5\" class=\"data row11 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col6\" class=\"data row11 col6\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col7\" class=\"data row11 col7\" >500</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col8\" class=\"data row11 col8\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col9\" class=\"data row11 col9\" >2</td>\n",
       "                        <td id=\"T_f4a51562_153d_11ea_82f5_9cb6d0e5d098row11_col10\" class=\"data row11 col10\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x261771dee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "timelabel =  datetime.now().strftime(\"%H-%M-%S - %d-%m-%Y\")\n",
    "\n",
    "\n",
    "configs = [{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 500,\n",
    "    \"max_mu\": 2,\n",
    "    \"max_sigma\": 2,\n",
    "    \"max_skew\": 1\n",
    "},\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.05, 0.05, 0.05, 0.85],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 50,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 2,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "] \n",
    "\n",
    "columns = ['method', 'accuracy','predictions', \"model\", \"config\"] + list(configs[0].keys())\n",
    "results = pd.DataFrame(columns=columns)\n",
    "results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "#run analysis\n",
    "for i, c in enumerate(configs):\n",
    "    X_train, X_test, y_train, y_test = simulate_data(c[\"classes\"], c[\"n_vars\"], c[\"n\"], c[\"max_mu\"], c[\"max_sigma\"], c[\"max_skew\"])\n",
    "    \n",
    "    lda = classify_lda(X_train, X_test, y_train, y_test, c[\"classes\"], False)                                     \n",
    "    results = results.append({**lda, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    qda = classify_qda(X_train, X_test, y_train, y_test, c[\"classes\"])                                     \n",
    "    results = results.append({**qda, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    logit = classify_logit(X_train, X_test, y_train, y_test)                                     \n",
    "    results = results.append({**logit, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    for k in [5,10,50,100]:\n",
    "        knn = classify_knn(X_train, X_test, y_train, y_test, k)\n",
    "        results = results.append({**knn, **c, \"config\":i+1},ignore_index=True)\n",
    "\n",
    "    bayes = classify_naivebayes(X_train, X_test, y_train, y_test, c[\"classes\"])\n",
    "    results = results.append({**bayes, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    svm = classify_svm(X_train, X_test, y_train, y_test)\n",
    "    results = results.append({**svm, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    for n in [{\"d\":1,\"n\":len(c[\"classes\"]), \"e\":25}, {\"d\":4,\"n\":30, \"e\":10}, {\"d\":4,\"n\":50, \"e\":50}]:\n",
    "        neuralnet = classify_neuralnet(X_train, X_test, y_train, y_test, c[\"n_vars\"], len(c[\"classes\"]),  depth=n[\"d\"], nodes=n[\"n\"], epochs=n[\"e\"])                                 \n",
    "        results = results.append({**neuralnet, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    print(\"Results after config \"+str(i+1)+\" of \"+str(len(configs)))\n",
    "\n",
    "    results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "        \n",
    "    display(results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "    }))\n",
    "    \n",
    "\n",
    "    #saving results to file\n",
    "    results.drop(columns=['model']).to_pickle(\"./results/config \"+str(i+1)+\" of \"+str(len(configs))+\" \"+timelabel+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example to load old results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >method</th>        <th class=\"col_heading level0 col1\" >accuracy</th>        <th class=\"col_heading level0 col2\" >predictions</th>        <th class=\"col_heading level0 col3\" >config</th>        <th class=\"col_heading level0 col4\" >classes</th>        <th class=\"col_heading level0 col5\" >n_vars</th>        <th class=\"col_heading level0 col6\" >n</th>        <th class=\"col_heading level0 col7\" >max_mu</th>        <th class=\"col_heading level0 col8\" >max_sigma</th>        <th class=\"col_heading level0 col9\" >max_skew</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col0\" class=\"data row0 col0\" >Logit</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col1\" class=\"data row0 col1\" >56.364%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col2\" class=\"data row0 col2\" >[3. 2. 0. 0. 2. 1. 1. 2. 0. 1. 3. 0. 1. 2. 2. 3. 3. 1. 2. 1. 3. 2. 2. 3.\n",
       " 3. 3. 3. 2. 2. 3. 2. 1. 2. 3. 1. 1. 3. 2. 3. 2. 1. 1. 3. 1. 2. 1. 0. 3.\n",
       " 3. 0. 3. 2. 0. 3. 1. 3. 3. 1. 0. 2. 0. 1. 0. 1. 1. 0. 2. 3. 1. 3. 1. 3.\n",
       " 0. 2. 2. 1. 2. 1. 1. 1. 2. 3. 1. 2. 2. 0. 1. 3. 0. 0. 2. 3. 1. 3. 2. 1.\n",
       " 1. 0. 1. 1. 3. 2. 0. 3. 2. 0. 0. 3. 0. 2. 2. 3. 2. 0. 2. 2. 3. 2. 2. 0.\n",
       " 0. 2. 3. 1. 1. 1. 1. 2. 1. 2. 2. 0. 2. 1. 3. 2. 2. 1. 2. 2. 2. 1. 0. 3.\n",
       " 1. 2. 0. 0. 1. 3. 3. 1. 0. 3. 0. 3. 3. 0. 3. 3. 2. 2. 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col4\" class=\"data row0 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col5\" class=\"data row0 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col6\" class=\"data row0 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col7\" class=\"data row0 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col8\" class=\"data row0 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row0_col9\" class=\"data row0 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col0\" class=\"data row1 col0\" >KNN-5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col1\" class=\"data row1 col1\" >56.364%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col2\" class=\"data row1 col2\" >[3. 2. 1. 0. 2. 1. 1. 2. 0. 2. 3. 0. 1. 2. 1. 3. 3. 1. 3. 1. 0. 2. 2. 1.\n",
       " 2. 3. 3. 2. 0. 3. 2. 3. 0. 3. 1. 1. 0. 0. 3. 3. 2. 1. 2. 1. 2. 2. 0. 3.\n",
       " 3. 3. 2. 2. 0. 3. 0. 3. 3. 1. 0. 2. 0. 1. 0. 1. 1. 0. 2. 3. 2. 3. 2. 3.\n",
       " 2. 2. 2. 1. 2. 2. 1. 1. 2. 3. 2. 2. 2. 0. 2. 3. 0. 0. 2. 0. 1. 1. 2. 1.\n",
       " 1. 0. 1. 2. 3. 2. 0. 3. 0. 0. 0. 3. 0. 2. 1. 3. 2. 0. 2. 2. 2. 2. 0. 3.\n",
       " 3. 2. 3. 2. 1. 1. 3. 2. 1. 2. 2. 0. 2. 0. 3. 3. 2. 1. 2. 0. 2. 1. 0. 3.\n",
       " 1. 2. 0. 0. 2. 3. 2. 1. 1. 1. 0. 3. 3. 0. 0. 3. 1. 0. 3. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col4\" class=\"data row1 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col5\" class=\"data row1 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col6\" class=\"data row1 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col7\" class=\"data row1 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col8\" class=\"data row1 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row1_col9\" class=\"data row1 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row2\" class=\"row_heading level0 row2\" >5</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col0\" class=\"data row2 col0\" >KNN-50</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col1\" class=\"data row2 col1\" >56.364%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col2\" class=\"data row2 col2\" >[3. 2. 0. 0. 2. 3. 2. 2. 3. 1. 3. 0. 1. 2. 2. 3. 3. 1. 2. 1. 3. 2. 2. 3.\n",
       " 3. 3. 0. 2. 1. 3. 2. 1. 2. 3. 1. 1. 0. 0. 3. 2. 1. 1. 3. 1. 1. 2. 0. 3.\n",
       " 3. 0. 3. 2. 0. 2. 1. 3. 3. 1. 0. 2. 0. 1. 0. 1. 1. 0. 2. 3. 1. 0. 2. 3.\n",
       " 0. 2. 2. 1. 2. 1. 1. 1. 2. 3. 1. 2. 2. 0. 1. 1. 0. 0. 2. 0. 1. 3. 2. 1.\n",
       " 1. 0. 1. 2. 3. 2. 0. 3. 2. 0. 0. 3. 2. 2. 1. 3. 2. 0. 2. 2. 3. 2. 2. 0.\n",
       " 0. 2. 3. 1. 1. 2. 1. 2. 1. 2. 2. 0. 2. 1. 3. 2. 2. 1. 2. 2. 2. 1. 0. 3.\n",
       " 1. 2. 0. 1. 1. 3. 3. 1. 0. 3. 0. 3. 2. 0. 3. 3. 2. 2. 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col4\" class=\"data row2 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col5\" class=\"data row2 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col6\" class=\"data row2 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col7\" class=\"data row2 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col8\" class=\"data row2 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row2_col9\" class=\"data row2 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row3\" class=\"row_heading level0 row3\" >8</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col0\" class=\"data row3 col0\" >SVM</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col1\" class=\"data row3 col1\" >56.364%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col2\" class=\"data row3 col2\" >[3. 2. 1. 0. 2. 1. 1. 2. 0. 1. 3. 0. 1. 2. 2. 3. 3. 1. 2. 1. 3. 2. 2. 3.\n",
       " 3. 3. 3. 2. 2. 3. 2. 1. 2. 3. 1. 1. 0. 2. 3. 2. 1. 1. 3. 1. 1. 1. 0. 3.\n",
       " 3. 0. 3. 2. 0. 3. 1. 3. 3. 1. 0. 2. 0. 1. 0. 1. 1. 0. 2. 3. 1. 0. 1. 3.\n",
       " 0. 1. 2. 1. 2. 1. 1. 1. 2. 3. 1. 2. 1. 0. 1. 3. 0. 0. 2. 3. 1. 3. 2. 1.\n",
       " 1. 0. 1. 1. 3. 3. 0. 3. 2. 0. 0. 3. 0. 2. 2. 3. 2. 0. 2. 2. 3. 2. 2. 0.\n",
       " 3. 2. 3. 1. 1. 1. 1. 2. 1. 2. 2. 0. 2. 1. 3. 2. 2. 1. 2. 2. 2. 1. 0. 3.\n",
       " 1. 2. 0. 0. 1. 3. 3. 1. 0. 3. 0. 3. 3. 0. 3. 3. 2. 2. 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col4\" class=\"data row3 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col5\" class=\"data row3 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col6\" class=\"data row3 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col7\" class=\"data row3 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col8\" class=\"data row3 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row3_col9\" class=\"data row3 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row4\" class=\"row_heading level0 row4\" >6</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col0\" class=\"data row4 col0\" >KNN-100</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col1\" class=\"data row4 col1\" >55.758%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col2\" class=\"data row4 col2\" >[3. 2. 1. 0. 2. 1. 2. 2. 0. 1. 3. 0. 1. 2. 2. 2. 3. 1. 2. 1. 3. 2. 2. 3.\n",
       " 3. 3. 0. 2. 1. 3. 2. 1. 2. 3. 1. 1. 0. 0. 3. 2. 2. 1. 3. 1. 1. 1. 0. 3.\n",
       " 3. 0. 3. 2. 0. 2. 1. 3. 3. 1. 0. 2. 0. 1. 0. 1. 1. 0. 2. 3. 1. 0. 2. 3.\n",
       " 0. 1. 2. 1. 2. 1. 1. 1. 2. 3. 1. 2. 1. 0. 1. 3. 0. 0. 2. 3. 1. 3. 2. 1.\n",
       " 1. 0. 1. 1. 3. 2. 0. 3. 2. 0. 0. 3. 0. 2. 1. 3. 2. 1. 2. 2. 3. 2. 2. 0.\n",
       " 1. 2. 3. 1. 1. 1. 3. 2. 1. 2. 2. 0. 2. 1. 3. 2. 2. 1. 2. 2. 2. 1. 0. 3.\n",
       " 1. 2. 0. 1. 1. 3. 3. 1. 0. 3. 0. 3. 3. 0. 3. 3. 2. 2. 3. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col4\" class=\"data row4 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col5\" class=\"data row4 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col6\" class=\"data row4 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col7\" class=\"data row4 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col8\" class=\"data row4 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row4_col9\" class=\"data row4 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row5\" class=\"row_heading level0 row5\" >11</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col0\" class=\"data row5 col0\" >Net 30-30-30-30 E50</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col1\" class=\"data row5 col1\" >55.758%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col2\" class=\"data row5 col2\" >[3 2 1 0 2 3 2 2 1 1 3 0 1 2 2 2 3 1 2 1 3 2 2 3 2 3 3 2 1 3 2 1 2 1 1 1 0\n",
       " 2 3 2 2 3 3 1 1 1 0 3 3 3 3 2 0 3 1 3 3 1 0 2 0 1 0 1 3 0 2 3 1 3 2 3 0 2\n",
       " 2 2 2 1 1 1 2 3 2 2 2 0 2 1 0 0 2 3 1 3 2 0 1 0 1 2 3 2 0 3 2 0 0 3 2 2 1\n",
       " 3 2 0 2 2 3 2 2 0 0 2 3 2 1 3 3 2 1 2 2 0 2 1 3 3 2 1 2 1 2 1 0 1 1 2 0 1\n",
       " 1 3 3 1 1 3 0 3 3 3 3 3 2 2 1 2 2]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col3\" class=\"data row5 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col4\" class=\"data row5 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col5\" class=\"data row5 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col6\" class=\"data row5 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col7\" class=\"data row5 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col8\" class=\"data row5 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row5_col9\" class=\"data row5 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row6\" class=\"row_heading level0 row6\" >0</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col0\" class=\"data row6 col0\" >LDA</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col1\" class=\"data row6 col1\" >55.152%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col2\" class=\"data row6 col2\" >[3. 2. 1. 0. 2. 1. 1. 2. 0. 1. 3. 0. 1. 2. 2. 2. 3. 1. 2. 1. 3. 2. 2. 3.\n",
       " 2. 3. 0. 2. 2. 3. 2. 1. 2. 3. 1. 1. 0. 2. 3. 2. 1. 1. 3. 1. 1. 1. 0. 3.\n",
       " 3. 0. 3. 2. 0. 3. 1. 3. 3. 1. 0. 2. 0. 1. 0. 1. 1. 0. 2. 3. 1. 3. 1. 3.\n",
       " 0. 1. 2. 1. 2. 1. 1. 1. 2. 3. 1. 2. 2. 0. 1. 3. 0. 0. 2. 3. 1. 3. 2. 1.\n",
       " 1. 0. 1. 1. 3. 3. 0. 3. 2. 0. 0. 3. 0. 2. 2. 3. 2. 0. 2. 2. 3. 2. 2. 0.\n",
       " 0. 2. 3. 1. 1. 3. 1. 2. 1. 2. 2. 0. 2. 1. 3. 2. 2. 1. 2. 2. 2. 1. 0. 3.\n",
       " 1. 2. 0. 0. 1. 3. 3. 1. 1. 3. 0. 3. 3. 0. 3. 3. 2. 2. 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col3\" class=\"data row6 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col4\" class=\"data row6 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col5\" class=\"data row6 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col6\" class=\"data row6 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col7\" class=\"data row6 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col8\" class=\"data row6 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row6_col9\" class=\"data row6 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row7\" class=\"row_heading level0 row7\" >1</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col0\" class=\"data row7 col0\" >QDA</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col1\" class=\"data row7 col1\" >55.152%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col2\" class=\"data row7 col2\" >[3. 2. 0. 0. 2. 1. 3. 2. 3. 1. 3. 0. 1. 2. 2. 3. 3. 1. 2. 1. 3. 2. 2. 3.\n",
       " 3. 3. 0. 3. 1. 3. 2. 1. 2. 1. 1. 1. 0. 0. 3. 3. 2. 1. 3. 1. 1. 1. 0. 3.\n",
       " 3. 3. 3. 2. 0. 3. 1. 3. 3. 1. 0. 2. 0. 1. 0. 1. 3. 0. 2. 3. 1. 3. 3. 3.\n",
       " 0. 2. 2. 1. 2. 1. 1. 1. 2. 3. 2. 2. 2. 0. 1. 1. 0. 0. 2. 0. 1. 3. 2. 1.\n",
       " 1. 0. 1. 2. 3. 3. 0. 3. 2. 0. 0. 1. 0. 2. 1. 3. 2. 0. 2. 2. 3. 2. 2. 0.\n",
       " 0. 2. 3. 1. 1. 2. 1. 2. 1. 2. 2. 0. 2. 1. 3. 2. 2. 1. 2. 1. 2. 1. 0. 1.\n",
       " 1. 2. 0. 1. 1. 3. 3. 1. 0. 3. 0. 3. 3. 3. 3. 3. 2. 2. 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col3\" class=\"data row7 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col4\" class=\"data row7 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col5\" class=\"data row7 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col6\" class=\"data row7 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col7\" class=\"data row7 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col8\" class=\"data row7 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row7_col9\" class=\"data row7 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row8\" class=\"row_heading level0 row8\" >4</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col0\" class=\"data row8 col0\" >KNN-10</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col1\" class=\"data row8 col1\" >54.545%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col2\" class=\"data row8 col2\" >[3. 2. 1. 0. 2. 1. 2. 2. 0. 2. 3. 0. 1. 2. 0. 3. 3. 1. 3. 1. 0. 2. 2. 3.\n",
       " 0. 3. 3. 3. 1. 3. 1. 0. 0. 3. 1. 1. 0. 0. 3. 2. 2. 1. 2. 1. 2. 2. 0. 3.\n",
       " 3. 3. 3. 2. 1. 3. 1. 3. 3. 1. 0. 2. 2. 1. 0. 1. 1. 0. 2. 3. 2. 0. 2. 3.\n",
       " 2. 2. 2. 1. 2. 2. 1. 1. 2. 3. 2. 2. 2. 2. 1. 3. 0. 0. 2. 3. 1. 3. 2. 1.\n",
       " 1. 0. 1. 2. 3. 2. 0. 3. 0. 0. 0. 3. 0. 2. 1. 3. 2. 0. 2. 2. 3. 2. 2. 0.\n",
       " 3. 2. 3. 2. 1. 1. 1. 2. 1. 2. 2. 0. 2. 0. 3. 2. 2. 1. 2. 0. 2. 1. 0. 3.\n",
       " 1. 2. 0. 0. 1. 3. 3. 1. 0. 3. 0. 3. 3. 0. 3. 3. 2. 2. 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col3\" class=\"data row8 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col4\" class=\"data row8 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col5\" class=\"data row8 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col6\" class=\"data row8 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col7\" class=\"data row8 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col8\" class=\"data row8 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row8_col9\" class=\"data row8 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row9\" class=\"row_heading level0 row9\" >7</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col1\" class=\"data row9 col1\" >54.545%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col2\" class=\"data row9 col2\" >[3. 2. 1. 0. 2. 1. 2. 2. 0. 1. 3. 0. 1. 2. 2. 3. 3. 1. 2. 1. 3. 2. 2. 3.\n",
       " 3. 3. 0. 3. 1. 3. 2. 1. 2. 3. 1. 1. 0. 2. 3. 2. 2. 1. 3. 1. 1. 1. 0. 3.\n",
       " 3. 0. 3. 2. 0. 2. 1. 3. 3. 1. 0. 2. 0. 1. 0. 1. 1. 0. 2. 3. 1. 3. 2. 3.\n",
       " 0. 1. 2. 1. 2. 1. 1. 1. 2. 3. 1. 2. 2. 0. 1. 3. 0. 0. 2. 3. 1. 3. 2. 1.\n",
       " 1. 0. 1. 1. 3. 2. 0. 3. 2. 0. 0. 3. 0. 2. 1. 3. 2. 0. 2. 2. 3. 2. 2. 0.\n",
       " 0. 2. 3. 1. 1. 3. 1. 2. 1. 2. 2. 0. 2. 1. 3. 2. 2. 1. 2. 2. 2. 1. 0. 3.\n",
       " 1. 2. 0. 1. 1. 3. 3. 1. 0. 3. 0. 3. 3. 0. 3. 3. 2. 2. 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col3\" class=\"data row9 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col4\" class=\"data row9 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col5\" class=\"data row9 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col6\" class=\"data row9 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col7\" class=\"data row9 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col8\" class=\"data row9 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row9_col9\" class=\"data row9 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col0\" class=\"data row10 col0\" >Net 30-30-30-30 E10</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col1\" class=\"data row10 col1\" >48.485%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col2\" class=\"data row10 col2\" >[3 2 1 0 2 2 2 2 1 1 2 1 1 2 2 2 3 1 2 1 3 2 2 3 2 0 1 2 1 1 2 1 2 1 1 1 0\n",
       " 2 2 2 2 3 2 1 1 1 0 3 2 0 2 2 0 2 1 3 2 1 0 2 1 1 2 1 2 0 2 3 2 3 2 2 2 2\n",
       " 2 2 2 1 1 1 2 1 1 2 1 2 1 1 1 0 2 3 1 2 2 0 1 0 2 1 2 2 1 3 2 0 1 1 1 2 1\n",
       " 1 2 1 2 2 2 2 2 0 1 2 1 1 1 1 1 2 1 2 2 0 2 1 3 2 2 1 2 1 2 1 0 1 1 2 0 1\n",
       " 1 3 2 1 0 1 0 2 2 0 3 1 2 2 1 2 2]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col3\" class=\"data row10 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col4\" class=\"data row10 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col5\" class=\"data row10 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col6\" class=\"data row10 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col7\" class=\"data row10 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col8\" class=\"data row10 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row10_col9\" class=\"data row10 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098level0_row11\" class=\"row_heading level0 row11\" >9</th>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col0\" class=\"data row11 col0\" >Net 4 E25</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col1\" class=\"data row11 col1\" >27.879%</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col2\" class=\"data row11 col2\" >[2 2 0 2 1 2 2 3 0 3 2 2 0 2 2 3 2 0 2 0 2 2 1 2 2 2 2 2 1 2 1 0 2 2 2 2 2\n",
       " 1 2 2 1 2 2 0 3 3 0 2 2 2 3 2 0 2 2 2 2 2 2 2 0 0 2 0 2 1 2 2 2 2 2 2 2 3\n",
       " 2 2 2 3 2 0 2 2 3 2 3 2 0 2 2 2 2 2 0 2 2 2 0 0 2 3 2 2 0 2 2 2 2 2 3 1 1\n",
       " 2 2 3 1 2 2 1 1 2 2 2 2 3 0 3 2 1 3 3 2 3 2 2 2 2 1 1 2 2 1 0 0 2 0 1 3 0\n",
       " 3 2 2 0 0 2 3 2 3 2 2 2 2 2 0 1 2]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col3\" class=\"data row11 col3\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col4\" class=\"data row11 col4\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col5\" class=\"data row11 col5\" >5</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col6\" class=\"data row11 col6\" >500</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col7\" class=\"data row11 col7\" >1</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col8\" class=\"data row11 col8\" >2</td>\n",
       "                        <td id=\"T_e89d495c_1538_11ea_aff5_9cb6d0e5d098row11_col9\" class=\"data row11 col9\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x207f4aaccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old_results = pd.read_pickle(\"./results/config 1 of 1 20-19-32 - 02-12-2019.pkl\")\n",
    "\n",
    "display(old_results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "    }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
