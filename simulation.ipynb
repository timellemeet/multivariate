{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate PythonGPU\n",
    "import numpy as np\n",
    "from scipy.stats import skewnorm, skew\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, accuracy_score\n",
    "\n",
    "def simulate_data(classes, n_vars, n, max_mu, max_sigma, max_skew, random_state=1234):\n",
    "    #The multivariate skew normal number generator\n",
    "    def rng(mu, sigma, skew, n=1):\n",
    "        k = len(mu)\n",
    "        if not (k == len(sigma) and k ==len(skew)): \n",
    "            raise Exception(\"Mu, Sigma and Skew should be same length\")\n",
    "\n",
    "        data = np.zeros((int(n),k))\n",
    "\n",
    "        for i in range(k):\n",
    "            data[:,i] = skewnorm.rvs(skew[i], loc=mu[i], scale=sigma[i], size=int(n)) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    if(np.sum(classes) != 1):\n",
    "        raise Exception(\"Classes dont sum up to 1\")\n",
    "        \n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    sigma = (max_sigma * np.random.rand(1,n_vars))[0]\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    skew = ((2 * max_skew  * np.random.rand(1, n_vars)) - max_skew)[0]\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    mu = (2 *  max_mu * np.random.rand(n_classes, n_vars)) - max_mu\n",
    "    \n",
    "    n_obs_class = np.round(np.dot(classes,n))\n",
    "    \n",
    "    data = np.zeros((int(np.sum(n_obs_class)),n_vars+1))\n",
    "    for i in range(n_classes):\n",
    "        #calculate indexes\n",
    "        start = int(np.sum(n_obs_class[0:i]))\n",
    "        end = int(np.sum(n_obs_class[0:i+1]))\n",
    "        \n",
    "        #set the data\n",
    "        data[start:end,0] = i\n",
    "        data[start:end,1:] = rng(mu[i,:], sigma, skew, n_obs_class[i])\n",
    "        \n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def classify_lda(X_train, X_test, y_train, y_test, priors, plot=False):\n",
    "    lda = LinearDiscriminantAnalysis(priors=priors)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    predictions = lda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"LDA Test accuracy \"+ str(accuracy))\n",
    "    print(predictions)\n",
    "\n",
    "    if plot:    \n",
    "        plt.xlabel('LD1')\n",
    "        plt.ylabel('LD2')\n",
    "        plt.scatter(\n",
    "            X_lda[:,0],\n",
    "            X_lda[:,1],\n",
    "            c=y_train,\n",
    "            cmap='Accent',\n",
    "        )\n",
    "        \n",
    "    return {\"method\": \"LDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": lda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadratic\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify_qda(X_train, X_test, y_train, y_test, priors):\n",
    "    qda = QuadraticDiscriminantAnalysis(priors=priors)\n",
    "    X_qda = qda.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = qda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"QDA Test accuracy \"+ str(accuracy))\n",
    "\n",
    "    return {\"method\": \"QDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": qda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classify_logit(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                             multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Logistic Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Logit\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def classify_knn(X_train, X_test, y_train, y_test, n_neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    predictions = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"KNN-\"+str(n_neighbors)+\" Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"KNN-\"+str(n_neighbors), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": knn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def classify_naivebayes(X_train, X_test, y_train, y_test, priors):\n",
    "    NB = GaussianNB(priors)\n",
    "    NB.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = NB.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"Naive Bayes Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Naive Bayes\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": NB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def classify_svm(X_train, X_test, y_train, y_test):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"SVM Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"SVM\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": svm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "def classify_neuralnet(X_train, X_test, y_train, y_test, n_vars, n_classes, depth=1, nodes=10, epochs=20):\n",
    "    inputs = keras.Input(shape=(n_vars,), name='obs')\n",
    "    x = layers.Dense(nodes, activation='relu')(inputs)\n",
    "    \n",
    "    if(depth>1):\n",
    "        for i in range(depth-1):\n",
    "            x = layers.Dense(nodes, activation='relu')(x)\n",
    "            \n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='Dataset')\n",
    "\n",
    "    display(model.summary())\n",
    "\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=64,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    print(predictions)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Neural Network Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Net \"+\"-\".join([str(nodes) for i in range(depth)])+ \" E\"+str(epochs), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "timelabel =  datetime.now().strftime(\"%H-%M-%S - %d-%m-%Y\")\n",
    "\n",
    "\n",
    "configs = [{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 500,\n",
    "    \"max_mu\": 2,\n",
    "    \"max_sigma\": 2,\n",
    "    \"max_skew\": 1\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 5,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.05, 0.05, 0.05, 0.85],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 5,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 50,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 5,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.125 for x in range(8)],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 1000000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "}]\n",
    "\n",
    "\n",
    "\n",
    "columns = ['method', 'accuracy','predictions', \"model\", \"config\"] + list(configs[0].keys())\n",
    "results = pd.DataFrame(columns=columns)\n",
    "results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "})\n",
    "\n",
    "\n",
    "#run analysis\n",
    "for i, c in enumerate(configs):\n",
    "    X_train, X_test, y_train, y_test = simulate_data(c[\"classes\"], c[\"n_vars\"], c[\"n\"], c[\"max_mu\"], c[\"max_sigma\"], c[\"max_skew\"], 1234)\n",
    "    \n",
    "    c_n = i+1\n",
    "    \n",
    "    lda = classify_lda(X_train, X_test, y_train, y_test, c[\"classes\"], False)                                     \n",
    "    results = results.append({**lda, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    qda = classify_qda(X_train, X_test, y_train, y_test, c[\"classes\"])                                     \n",
    "    results = results.append({**qda, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    logit = classify_logit(X_train, X_test, y_train, y_test)                                     \n",
    "    results = results.append({**logit, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    for k in [5,10,50,100]:\n",
    "        knn = classify_knn(X_train, X_test, y_train, y_test, k)\n",
    "        results = results.append({**knn, **c, \"config\":c_n},ignore_index=True)\n",
    "\n",
    "    bayes = classify_naivebayes(X_train, X_test, y_train, y_test, c[\"classes\"])\n",
    "    results = results.append({**bayes, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    svm = classify_svm(X_train, X_test, y_train, y_test)\n",
    "    results = results.append({**svm, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    for n in [{\"d\":1,\"n\":len(c[\"classes\"]), \"e\":25}, {\"d\":4,\"n\":30, \"e\":10}, {\"d\":4,\"n\":50, \"e\":50}]:\n",
    "        neuralnet = classify_neuralnet(X_train, X_test, y_train, y_test, c[\"n_vars\"], len(c[\"classes\"]),  depth=n[\"d\"], nodes=n[\"n\"], epochs=n[\"e\"])                                 \n",
    "        results = results.append({**neuralnet, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    print(\"Results after config \"+str(c_n)+\" of \"+str(len(configs)))\n",
    "\n",
    "    results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "        \n",
    "    display(results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "    }))\n",
    "    \n",
    "\n",
    "    #saving results to file\n",
    "    results.drop(columns=['model']).to_pickle(\"./results/config \"+str(i+1)+\" of \"+str(len(configs))+\" \"+timelabel+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making tables for the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def bold(data):\n",
    "    attr = 'font-weight: {}'.format(\"700\")\n",
    "    #remove % and cast to float\n",
    "    data = data.replace('%','', regex=True).astype(float)\n",
    "    is_max = data == data.max()\n",
    "    return [attr if v else \"\" for v in is_max]\n",
    "    \n",
    "def boldlatex(data):\n",
    "    #remove % and cast to float\n",
    "    return list(map(lambda x: r\"\\textbf{\"+x+\"}\" if x==data.max() else x, data))\n",
    "   \n",
    "table = results.copy()\n",
    "table['accuracy'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in table['accuracy']], index = table.index)\n",
    "table.loc[table.method == \"Net 2 E25\", \"method\"] = \"Net N_C E25\"\n",
    "table.loc[table.method == \"Net 4 E25\", \"method\"] = \"Net N_C E25\"\n",
    "table.loc[table.method == \"Net 8 E25\", \"method\"] = \"Net N_C E25\"\n",
    "\n",
    "table = table.pivot(index='method', columns='config', values='accuracy').sort_values(by='method')\n",
    "display(table.style.apply(bold))\n",
    "latex = table.apply(boldlatex).to_latex()\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.DataFrame.from_dict(configs)\n",
    "datasets = datasets[['max_mu', 'max_sigma', 'max_skew', 'n_vars', 'n', 'classes',]]\n",
    "datasets.insert(0, \"dataset\", datasets.index+1)\n",
    "datasets = datasets.transpose()\n",
    "display(datasets)\n",
    "\n",
    "print(datasets.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
