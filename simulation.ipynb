{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate PythonGPU\n",
    "import numpy as np\n",
    "from scipy.stats import skewnorm, skew\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, accuracy_score\n",
    "\n",
    "def simulate_data(classes, n_vars, n, max_mu, max_sigma, max_skew):\n",
    "    #The multivariate skew normal number generator\n",
    "    def rng(mu, sigma, skew, n=1):\n",
    "        k = len(mu)\n",
    "        if not (k == len(sigma) and k ==len(skew)): \n",
    "            raise Exception(\"Mu, Sigma and Skew should be same length\")\n",
    "\n",
    "        data = np.zeros((int(n),k))\n",
    "\n",
    "        for i in range(k):\n",
    "            data[:,i] = skewnorm.rvs(skew[i], loc=mu[i], scale=sigma[i], size=int(n)) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    if(np.sum(classes) != 1):\n",
    "        raise Exception(\"Classes dont sum up to 1\")\n",
    "        \n",
    "    n_classes = len(classes)\n",
    "    sigma = np.random.randint(1,max_sigma,n_vars)\n",
    "    skew = np.random.randint(-max_skew,max_skew,n_vars)\n",
    "    mu =  np.random.randint(-max_mu, max_mu, (n_classes, n_vars))\n",
    "    \n",
    "    n_obs_class = np.round(np.dot(classes,n))\n",
    "    \n",
    "    data = np.zeros((int(np.sum(n_obs_class)),n_vars+1))\n",
    "    for i in range(n_classes):\n",
    "        #calculate indexes\n",
    "        start = int(np.sum(n_obs_class[0:i]))\n",
    "        end = int(np.sum(n_obs_class[0:i+1]))\n",
    "        \n",
    "        #set the data\n",
    "        data[start:end,0] = i\n",
    "        data[start:end,1:] = rng(mu[i,:], sigma, skew, n_obs_class[i])\n",
    "        \n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "    \n",
    "#     columns = [\"x\"+str(x) for x in range(n_vars + 1)]\n",
    "#     columns[0] = \"class\"\n",
    "    \n",
    "#     df = pd.DataFrame(data,columns=columns)\n",
    "#     df[\"class\"] = df[\"class\"].astype(int)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def classify_lda(X_train, X_test, y_train, y_test, priors):\n",
    "    lda = LinearDiscriminantAnalysis(priors=priors)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    predictions = lda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"LDA Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    report = classification_report(y_test, predictions)\n",
    "    print(report)\n",
    "\n",
    "    \n",
    "#     plt.xlabel('LD1')\n",
    "#     plt.ylabel('LD2')\n",
    "#     plt.scatter(\n",
    "#         X_lda[:,0],\n",
    "#         X_lda[:,1],\n",
    "#         c=y_train,\n",
    "#         cmap='Accent',\n",
    "#     )\n",
    "    return {\"method\": \"LDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"report\": report,\n",
    "            \"model\": lda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Test accuracy 0.5025151515151515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.21      0.28      8250\n",
      "         1.0       0.89      0.86      0.87      8250\n",
      "         2.0       0.37      0.55      0.44      8250\n",
      "         3.0       0.38      0.39      0.39      8250\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     33000\n",
      "   macro avg       0.51      0.50      0.49     33000\n",
      "weighted avg       0.51      0.50      0.49     33000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Quadratic\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis(priors=classes)\n",
    "X_qda = qda.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "qda_pred = qda.predict(X_test)\n",
    "qda_acc = accuracy_score(y_test, qda_pred)\n",
    "print(\"QDA Test accuracy \"+ str(qda_acc))\n",
    "# confusion_matrix(y_test, lda_pred)\n",
    "print(classification_report(y_test, qda_pred))\n",
    "\n",
    "accuracies = accuracies.append({\"method\": \"QDA\", \n",
    "                   \"accuracy\":qda_acc, \n",
    "                   \"predictions\":qda_pred}, \n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Test accuracy 0.49542424242424243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.30      0.34      8250\n",
      "         1.0       0.86      0.87      0.86      8250\n",
      "         2.0       0.36      0.52      0.43      8250\n",
      "         3.0       0.39      0.29      0.33      8250\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     33000\n",
      "   macro avg       0.50      0.50      0.49     33000\n",
      "weighted avg       0.50      0.50      0.49     33000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf_pred = clf.predict(X_test)\n",
    "clf_acc = accuracy_score(y_test, clf_pred)\n",
    "print(\"Logistic Test accuracy \"+ str(clf_acc))\n",
    "\n",
    "accuracies = accuracies.append({\"method\": \"Logit\", \n",
    "                   \"accuracy\":clf_acc, \n",
    "                   \"predictions\":clf_pred}, \n",
    "                    ignore_index=True)\n",
    "\n",
    "# confusion_matrix(y_test, lda_pred)\n",
    "print(classification_report(y_test, clf_pred))\n",
    "\n",
    "# plt.xlabel('LD1')\n",
    "# plt.ylabel('LD2')\n",
    "# plt.scatter(\n",
    "#     clf[:,0],\n",
    "#     clf[:,1],\n",
    "#     c=y_train,\n",
    "#     cmap='Accent',\n",
    "# #      alpha=0.7,\n",
    "# #      edgecolors='grey'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Dataset\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "obs (InputLayer)             [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 40)                120       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 3,810\n",
      "Trainable params: 3,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53600 samples, validate on 13400 samples\n",
      "Epoch 1/20\n",
      "53600/53600 [==============================] - 5s 86us/sample - loss: 1.0121 - accuracy: 0.4938 - val_loss: 0.9416 - val_accuracy: 0.5107\n",
      "Epoch 2/20\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 0.9350 - accuracy: 0.5076 - val_loss: 0.9275 - val_accuracy: 0.5122\n",
      "Epoch 3/20\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 0.9303 - accuracy: 0.5105 - val_loss: 0.9261 - val_accuracy: 0.5159\n",
      "Epoch 4/20\n",
      "53600/53600 [==============================] - 4s 71us/sample - loss: 0.9288 - accuracy: 0.5107 - val_loss: 0.9264 - val_accuracy: 0.5116\n",
      "Epoch 5/20\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 0.9280 - accuracy: 0.5122 - val_loss: 0.9234 - val_accuracy: 0.5115\n",
      "Epoch 6/20\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 0.9274 - accuracy: 0.5130 - val_loss: 0.9248 - val_accuracy: 0.5172\n",
      "Epoch 7/20\n",
      "53600/53600 [==============================] - 4s 71us/sample - loss: 0.9265 - accuracy: 0.5128 - val_loss: 0.9307 - val_accuracy: 0.5122\n",
      "Epoch 8/20\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 0.9268 - accuracy: 0.5130 - val_loss: 0.9297 - val_accuracy: 0.5131\n",
      "Epoch 9/20\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 0.9262 - accuracy: 0.5132 - val_loss: 0.9226 - val_accuracy: 0.5150\n",
      "Epoch 10/20\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 0.9257 - accuracy: 0.5154 - val_loss: 0.9235 - val_accuracy: 0.5151\n",
      "Epoch 11/20\n",
      "53600/53600 [==============================] - 4s 71us/sample - loss: 0.9260 - accuracy: 0.5144 - val_loss: 0.9237 - val_accuracy: 0.5110\n",
      "Epoch 12/20\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 0.9257 - accuracy: 0.5151 - val_loss: 0.9223 - val_accuracy: 0.5181\n",
      "Epoch 13/20\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 0.9258 - accuracy: 0.5167 - val_loss: 0.9249 - val_accuracy: 0.5151\n",
      "Epoch 14/20\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 0.9254 - accuracy: 0.5133 - val_loss: 0.9260 - val_accuracy: 0.5151s - loss: 0.9253 - accuracy: 0.51\n",
      "Epoch 15/20\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 0.9253 - accuracy: 0.5144 - val_loss: 0.9240 - val_accuracy: 0.5152\n",
      "Epoch 16/20\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 0.9256 - accuracy: 0.5144 - val_loss: 0.9285 - val_accuracy: 0.5171\n",
      "Epoch 17/20\n",
      "53600/53600 [==============================] - 4s 71us/sample - loss: 0.9252 - accuracy: 0.5148 - val_loss: 0.9227 - val_accuracy: 0.5128\n",
      "Epoch 18/20\n",
      "53600/53600 [==============================] - 4s 73us/sample - loss: 0.9254 - accuracy: 0.5138 - val_loss: 0.9251 - val_accuracy: 0.5117\n",
      "Epoch 19/20\n",
      "53600/53600 [==============================] - 4s 69us/sample - loss: 0.9258 - accuracy: 0.5137 - val_loss: 0.9236 - val_accuracy: 0.5126\n",
      "Epoch 20/20\n",
      "53600/53600 [==============================] - 4s 71us/sample - loss: 0.9253 - accuracy: 0.5151 - val_loss: 0.9308 - val_accuracy: 0.5122\n",
      "33000/1 - 2s - loss: 0.7437 - accuracy: 0.5150\n",
      "Test loss: 0.9293298399809635\n",
      "Test accuracy: 0.5150303\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(n_vars,), name='obs')\n",
    "x = layers.Dense(40, activation='relu')(inputs)\n",
    "x = layers.Dense(40, activation='relu')(x)\n",
    "x = layers.Dense(40, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='Dataset')\n",
    "\n",
    "display(model.summary())\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "\n",
    "accuracies = accuracies.append({\"method\": \"Neural Net\", \n",
    "                   \"accuracy\": test_scores[1], \n",
    "                   \"predictions\":clf_pred}, \n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.500727</td>\n",
       "      <td>[3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.502515</td>\n",
       "      <td>[3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logit</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>[3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.515030</td>\n",
       "      <td>[3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       method  accuracy                                        predictions\n",
       "0         LDA  0.500727  [3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, ...\n",
       "1         QDA  0.502515  [3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, ...\n",
       "2       Logit  0.495424  [3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, ...\n",
       "3  Neural Net  0.515030  [3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, ..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test accuracy 0.5007272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.32      0.35      8250\n",
      "         1.0       0.89      0.86      0.87      8250\n",
      "         2.0       0.37      0.56      0.44      8250\n",
      "         3.0       0.39      0.28      0.32      8250\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     33000\n",
      "   macro avg       0.51      0.50      0.50     33000\n",
      "weighted avg       0.51      0.50      0.50     33000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>predictions</th>\n",
       "      <th>report</th>\n",
       "      <th>model</th>\n",
       "      <th>config</th>\n",
       "      <th>classes</th>\n",
       "      <th>n_vars</th>\n",
       "      <th>n</th>\n",
       "      <th>max_mu</th>\n",
       "      <th>max_sigma</th>\n",
       "      <th>max_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.500727</td>\n",
       "      <td>[3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>2</td>\n",
       "      <td>100000</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  accuracy                                        predictions  \\\n",
       "0    LDA  0.500727  [3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, ...   \n",
       "\n",
       "                                              report  \\\n",
       "0                precision    recall  f1-score   ...   \n",
       "\n",
       "                                               model config  \\\n",
       "0  LinearDiscriminantAnalysis(n_components=None, ...      1   \n",
       "\n",
       "                    classes n_vars       n max_mu max_sigma max_skew  \n",
       "0  [0.25, 0.25, 0.25, 0.25]      2  100000      4        30       10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "configs = [{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 4,\n",
    "    \"max_sigma\": 30,\n",
    "    \"max_skew\": 10\n",
    "}] \n",
    "\n",
    "\n",
    "columns = ['method', 'accuracy','predictions', \"report\", \"model\", \"config\"] + list(configs[0].keys())\n",
    "\n",
    "results = pd.DataFrame(columns=columns)\n",
    "\n",
    "#                                 ['method', \n",
    "#                                 'accuracy', \n",
    "#                                 'predictions', \n",
    "#                                 \"report\", \n",
    "#                                 \"model\", \n",
    "#                                 \"classes\", \n",
    "#                                 \"n_vars\", \n",
    "#                                 \"n\", \n",
    "#                                 \"max_mu\", \n",
    "#                                 \"max_sigma\", \n",
    "#                                 \"max_skew\"]\n",
    "\n",
    "\n",
    "for i, c in enumerate(configs):\n",
    "    X_train, X_test, y_train, y_test = simulate_data(c[\"classes\"], c[\"n_vars\"], c[\"n\"], c[\"max_mu\"], c[\"max_sigma\"], c[\"max_skew\"])\n",
    "    \n",
    "    lda = classify_lda(X_train, X_test, y_train, y_test, classes)                                     \n",
    "    results = results.append({**lda, **c, \"config\":i+1},ignore_index=True)\n",
    "# res = \n",
    "# dict3 = {**dict1 , **dict2}\n",
    "\n",
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
