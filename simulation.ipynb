{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate PythonGPU\n",
    "import numpy as np\n",
    "from scipy.stats import skewnorm, skew\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, accuracy_score\n",
    "\n",
    "def simulate_data(classes, n_vars, n, max_mu, max_sigma, max_skew):\n",
    "    #The multivariate skew normal number generator\n",
    "    def rng(mu, sigma, skew, n=1):\n",
    "        k = len(mu)\n",
    "        if not (k == len(sigma) and k ==len(skew)): \n",
    "            raise Exception(\"Mu, Sigma and Skew should be same length\")\n",
    "\n",
    "        data = np.zeros((int(n),k))\n",
    "\n",
    "        for i in range(k):\n",
    "            data[:,i] = skewnorm.rvs(skew[i], loc=mu[i], scale=sigma[i], size=int(n)) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    if(np.sum(classes) != 1):\n",
    "        raise Exception(\"Classes dont sum up to 1\")\n",
    "        \n",
    "    n_classes = len(classes)\n",
    "#     sigma = np.random.randint(1,max_sigma,n_vars)\n",
    "#     skew = np.random.randint(-max_skew,max_skew,n_vars)\n",
    "#     mu =  np.random.randint(-max_mu, max_mu, (n_classes, n_vars))\n",
    "    \n",
    "    sigma = (max_sigma * np.random.rand(1,n_vars))[0]\n",
    "    skew = ((2 * max_skew  * np.random.rand(1, n_vars)) - max_skew)[0]\n",
    "    mu = (2 *  max_mu * np.random.rand(n_classes, n_vars)) - max_mu\n",
    "    \n",
    "    n_obs_class = np.round(np.dot(classes,n))\n",
    "    \n",
    "    data = np.zeros((int(np.sum(n_obs_class)),n_vars+1))\n",
    "    for i in range(n_classes):\n",
    "        #calculate indexes\n",
    "        start = int(np.sum(n_obs_class[0:i]))\n",
    "        end = int(np.sum(n_obs_class[0:i+1]))\n",
    "        \n",
    "        #set the data\n",
    "        data[start:end,0] = i\n",
    "        data[start:end,1:] = rng(mu[i,:], sigma, skew, n_obs_class[i])\n",
    "        \n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def classify_lda(X_train, X_test, y_train, y_test, priors, plot=False):\n",
    "    lda = LinearDiscriminantAnalysis(priors=priors)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    predictions = lda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"LDA Test accuracy \"+ str(accuracy))\n",
    "    print(predictions)\n",
    "\n",
    "    if plot:    \n",
    "        plt.xlabel('LD1')\n",
    "        plt.ylabel('LD2')\n",
    "        plt.scatter(\n",
    "            X_lda[:,0],\n",
    "            X_lda[:,1],\n",
    "            c=y_train,\n",
    "            cmap='Accent',\n",
    "        )\n",
    "        \n",
    "    return {\"method\": \"LDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": lda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadratic\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify_qda(X_train, X_test, y_train, y_test, priors):\n",
    "    qda = QuadraticDiscriminantAnalysis(priors=priors)\n",
    "    X_qda = qda.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = qda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"QDA Test accuracy \"+ str(accuracy))\n",
    "\n",
    "    return {\"method\": \"QDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": qda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classify_logit(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                             multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Logistic Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Logit\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def classify_knn(X_train, X_test, y_train, y_test, n_neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    predictions = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"KNN-\"+str(n_neighbors)+\" Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"KNN-\"+str(n_neighbors), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": knn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def classify_naivebayes(X_train, X_test, y_train, y_test, priors):\n",
    "    NB = GaussianNB(priors)\n",
    "    NB.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = NB.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"Naive Bayes Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Naive Bayes\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": NB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def classify_svm(X_train, X_test, y_train, y_test):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"SVM Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"SVM\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": svm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "def classify_neuralnet(X_train, X_test, y_train, y_test, n_vars, n_classes, depth=1, nodes=10, epochs=20):\n",
    "    inputs = keras.Input(shape=(n_vars,), name='obs')\n",
    "    x = layers.Dense(nodes, activation='relu')(inputs)\n",
    "    \n",
    "    if(depth>1):\n",
    "        for i in range(depth-1):\n",
    "            x = layers.Dense(nodes, activation='relu')(x)\n",
    "            \n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='Dataset')\n",
    "\n",
    "    display(model.summary())\n",
    "\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=64,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    print(predictions)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Neural Network Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Net \"+\"-\".join([str(nodes) for i in range(depth)])+ \" E\"+str(epochs), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test accuracy 0.4674242424242424\n",
      "[3. 0. 0. ... 1. 2. 2.]\n",
      "QDA Test accuracy 0.4656060606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Test accuracy 0.46736363636363637\n",
      "KNN-5 Test accuracy 0.42696969696969694\n",
      "KNN-10 Test accuracy 0.44966666666666666\n",
      "KNN-50 Test accuracy 0.4709090909090909\n",
      "KNN-100 Test accuracy 0.47563636363636363\n",
      "Naive Bayes Test accuracy 0.4661212121212121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test accuracy 0.45566666666666666\n",
      "Model: \"Dataset\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "obs (InputLayer)             [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 44\n",
      "Trainable params: 44\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53600 samples, validate on 13400 samples\n",
      "Epoch 1/25\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 1.6226 - accuracy: 0.3592 - val_loss: 1.2524 - val_accuracy: 0.4019\n",
      "Epoch 2/25\n",
      "53600/53600 [==============================] - 3s 61us/sample - loss: 1.2152 - accuracy: 0.4248 - val_loss: 1.1847 - val_accuracy: 0.4413ss: 1.2176 - accuracy\n",
      "Epoch 3/25\n",
      "53600/53600 [==============================] - 3s 60us/sample - loss: 1.1621 - accuracy: 0.4554 - val_loss: 1.1455 - val_accuracy: 0.4613ETA: 0s - l - ETA: 0s - loss: 1.1630 - accuracy: 0.\n",
      "Epoch 4/25\n",
      "53600/53600 [==============================] - 3s 58us/sample - loss: 1.1348 - accuracy: 0.4694 - val_loss: 1.1243 - val_accuracy: 0.4735\n",
      "Epoch 5/25\n",
      "53600/53600 [==============================] - 3s 57us/sample - loss: 1.1188 - accuracy: 0.4788 - val_loss: 1.1114 - val_accuracy: 0.4843\n",
      "Epoch 6/25\n",
      "53600/53600 [==============================] - 3s 58us/sample - loss: 1.1087 - accuracy: 0.4832 - val_loss: 1.1032 - val_accuracy: 0.4872s - loss: 1.1105 - accuracy: 0.48 - ETA: 0s - loss: 1.1\n",
      "Epoch 7/25\n",
      "53600/53600 [==============================] - 3s 56us/sample - loss: 1.1015 - accuracy: 0.4865 - val_loss: 1.0972 - val_accuracy: 0.4915 accu - ETA: 1s - loss: 1.1041  - ETA: 1s - los - ETA: 0s - loss: 1.1024 - accu\n",
      "Epoch 8/25\n",
      "53600/53600 [==============================] - 3s 60us/sample - loss: 1.0975 - accuracy: 0.4893 - val_loss: 1.0934 - val_accuracy: 0.492572 - accuracy: 0.\n",
      "Epoch 9/25\n",
      "53600/53600 [==============================] - 3s 58us/sample - loss: 1.0948 - accuracy: 0.4909 - val_loss: 1.0913 - val_accuracy: 0.4960A: 0s - loss: 1.0\n",
      "Epoch 10/25\n",
      "53600/53600 [==============================] - 3s 58us/sample - loss: 1.0929 - accuracy: 0.4921 - val_loss: 1.0909 - val_accuracy: 0.4959 - accu - ETA: 0s - loss: 1.0928 - accuracy\n",
      "Epoch 11/25\n",
      "53600/53600 [==============================] - 3s 56us/sample - loss: 1.0919 - accuracy: 0.4918 - val_loss: 1.0897 - val_accuracy: 0.4953\n",
      "Epoch 12/25\n",
      "53600/53600 [==============================] - 3s 56us/sample - loss: 1.0907 - accuracy: 0.4922 - val_loss: 1.0885 - val_accuracy: 0.4980\n",
      "Epoch 13/25\n",
      "53600/53600 [==============================] - 3s 57us/sample - loss: 1.0900 - accuracy: 0.4938 - val_loss: 1.0865 - val_accuracy: 0.500017 - accuracy: 0.49 - ETA: 0s - los\n",
      "Epoch 14/25\n",
      "53600/53600 [==============================] - 3s 55us/sample - loss: 1.0897 - accuracy: 0.4938 - val_loss: 1.0867 - val_accuracy: 0.4967\n",
      "Epoch 15/25\n",
      "53600/53600 [==============================] - 3s 55us/sample - loss: 1.0893 - accuracy: 0.4945 - val_loss: 1.0875 - val_accuracy: 0.5006\n",
      "Epoch 16/25\n",
      "53600/53600 [==============================] - 3s 56us/sample - loss: 1.0890 - accuracy: 0.4946 - val_loss: 1.0852 - val_accuracy: 0.5018loss: 1.0928 - accuracy:  - ETA: 1s - loss: 1.0936 - accuracy: 0. - ETA: 1s - loss: 1.0921  - ETA: 1s - - ETA: 0s - loss: 1.0888 - accuracy\n",
      "Epoch 17/25\n",
      "53600/53600 [==============================] - 3s 61us/sample - loss: 1.0885 - accuracy: 0.4960 - val_loss: 1.0873 - val_accuracy: 0.5013\n",
      "Epoch 18/25\n",
      "53600/53600 [==============================] - 4s 71us/sample - loss: 1.0883 - accuracy: 0.4942 - val_loss: 1.0856 - val_accuracy: 0.5024\n",
      "Epoch 19/25\n",
      "53600/53600 [==============================] - 3s 62us/sample - loss: 1.0880 - accuracy: 0.4962 - val_loss: 1.0845 - val_accuracy: 0.5016\n",
      "Epoch 20/25\n",
      "53600/53600 [==============================] - 3s 58us/sample - loss: 1.0876 - accuracy: 0.4955 - val_loss: 1.0845 - val_accuracy: 0.5010\n",
      "Epoch 21/25\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 1.0873 - accuracy: 0.4945 - val_loss: 1.0838 - val_accuracy: 0.5016\n",
      "Epoch 22/25\n",
      "53600/53600 [==============================] - 3s 62us/sample - loss: 1.0874 - accuracy: 0.4956 - val_loss: 1.0841 - val_accuracy: 0.5008\n",
      "Epoch 23/25\n",
      "53600/53600 [==============================] - 3s 62us/sample - loss: 1.0871 - accuracy: 0.4945 - val_loss: 1.0861 - val_accuracy: 0.4963loss: 1.0878 - \n",
      "Epoch 24/25\n",
      "53600/53600 [==============================] - 3s 63us/sample - loss: 1.0872 - accuracy: 0.4945 - val_loss: 1.0843 - val_accuracy: 0.4996\n",
      "Epoch 25/25\n",
      "53600/53600 [==============================] - 3s 64us/sample - loss: 1.0869 - accuracy: 0.4953 - val_loss: 1.0841 - val_accuracy: 0.5012s - loss: 1.0\n",
      "[3 0 0 ... 1 2 2]\n",
      "Neural Network Test accuracy 0.49218181818181816\n",
      "Model: \"Dataset\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "obs (InputLayer)             [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                180       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 124       \n",
      "=================================================================\n",
      "Total params: 3,094\n",
      "Trainable params: 3,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53600 samples, validate on 13400 samples\n",
      "Epoch 1/10\n",
      "53600/53600 [==============================] - 6s 106us/sample - loss: 1.1501 - accuracy: 0.4649 - val_loss: 1.1184 - val_accuracy: 0.4746\n",
      "Epoch 2/10\n",
      "53600/53600 [==============================] - 4s 83us/sample - loss: 1.0940 - accuracy: 0.4922 - val_loss: 1.0885 - val_accuracy: 0.4954\n",
      "Epoch 3/10\n",
      "53600/53600 [==============================] - 5s 97us/sample - loss: 1.0862 - accuracy: 0.4960 - val_loss: 1.0844 - val_accuracy: 0.4998\n",
      "Epoch 4/10\n",
      "53600/53600 [==============================] - 4s 83us/sample - loss: 1.0832 - accuracy: 0.4971 - val_loss: 1.0781 - val_accuracy: 0.5014s - loss: 1.084\n",
      "Epoch 5/10\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 1.0797 - accuracy: 0.4981 - val_loss: 1.0801 - val_accuracy: 0.4985\n",
      "Epoch 6/10\n",
      "53600/53600 [==============================] - 4s 73us/sample - loss: 1.0778 - accuracy: 0.4992 - val_loss: 1.0792 - val_accuracy: 0.5004\n",
      "Epoch 7/10\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0766 - accuracy: 0.4995 - val_loss: 1.0811 - val_accuracy: 0.4995\n",
      "Epoch 8/10\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 1.0754 - accuracy: 0.5026 - val_loss: 1.0762 - val_accuracy: 0.5040\n",
      "Epoch 9/10\n",
      "53600/53600 [==============================] - 4s 75us/sample - loss: 1.0755 - accuracy: 0.5017 - val_loss: 1.0814 - val_accuracy: 0.4985\n",
      "Epoch 10/10\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0750 - accuracy: 0.5016 - val_loss: 1.0847 - val_accuracy: 0.5022\n",
      "[3 0 0 ... 1 2 1]\n",
      "Neural Network Test accuracy 0.49657575757575756\n",
      "Model: \"Dataset\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "obs (InputLayer)             [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                300       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 8,154\n",
      "Trainable params: 8,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53600 samples, validate on 13400 samples\n",
      "Epoch 1/50\n",
      "53600/53600 [==============================] - 5s 91us/sample - loss: 1.1325 - accuracy: 0.4733 - val_loss: 1.1049 - val_accuracy: 0.4931\n",
      "Epoch 2/50\n",
      "53600/53600 [==============================] - 4s 73us/sample - loss: 1.0927 - accuracy: 0.4937 - val_loss: 1.0906 - val_accuracy: 0.4939\n",
      "Epoch 3/50\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 1.0852 - accuracy: 0.4978 - val_loss: 1.0789 - val_accuracy: 0.4998\n",
      "Epoch 4/50\n",
      "53600/53600 [==============================] - 4s 81us/sample - loss: 1.0814 - accuracy: 0.4976 - val_loss: 1.0835 - val_accuracy: 0.4981\n",
      "Epoch 5/50\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 1.0791 - accuracy: 0.5002 - val_loss: 1.0807 - val_accuracy: 0.4987\n",
      "Epoch 6/50\n",
      "53600/53600 [==============================] - 4s 82us/sample - loss: 1.0782 - accuracy: 0.4998 - val_loss: 1.0784 - val_accuracy: 0.5016\n",
      "Epoch 7/50\n",
      "53600/53600 [==============================] - 5s 92us/sample - loss: 1.0770 - accuracy: 0.4999 - val_loss: 1.0788 - val_accuracy: 0.4996\n",
      "Epoch 8/50\n",
      "53600/53600 [==============================] - 4s 81us/sample - loss: 1.0766 - accuracy: 0.5006 - val_loss: 1.0776 - val_accuracy: 0.5006\n",
      "Epoch 9/50\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 1.0760 - accuracy: 0.5006 - val_loss: 1.0796 - val_accuracy: 0.4986\n",
      "Epoch 10/50\n",
      "53600/53600 [==============================] - 4s 83us/sample - loss: 1.0758 - accuracy: 0.5012 - val_loss: 1.0857 - val_accuracy: 0.4956\n",
      "Epoch 11/50\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0759 - accuracy: 0.5021 - val_loss: 1.0848 - val_accuracy: 0.5007\n",
      "Epoch 12/50\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0756 - accuracy: 0.5012 - val_loss: 1.0845 - val_accuracy: 0.5012\n",
      "Epoch 13/50\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0764 - accuracy: 0.5028 - val_loss: 1.0961 - val_accuracy: 0.4924\n",
      "Epoch 14/50\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 1.0762 - accuracy: 0.5028 - val_loss: 1.0957 - val_accuracy: 0.4926\n",
      "Epoch 15/50\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 1.0760 - accuracy: 0.5024 - val_loss: 1.0881 - val_accuracy: 0.4967\n",
      "Epoch 16/50\n",
      "53600/53600 [==============================] - 4s 78us/sample - loss: 1.0774 - accuracy: 0.5015 - val_loss: 1.0787 - val_accuracy: 0.5036\n",
      "Epoch 17/50\n",
      "53600/53600 [==============================] - 4s 75us/sample - loss: 1.0774 - accuracy: 0.5019 - val_loss: 1.0859 - val_accuracy: 0.4995\n",
      "Epoch 18/50\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0764 - accuracy: 0.5004 - val_loss: 1.0821 - val_accuracy: 0.4988\n",
      "Epoch 19/50\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 1.0766 - accuracy: 0.5014 - val_loss: 1.0805 - val_accuracy: 0.5007ss: 1 - ETA: 0s - loss: 1.0740 - accu - ETA: 0s - loss: 1.0751 - accu\n",
      "Epoch 20/50\n",
      "53600/53600 [==============================] - 4s 73us/sample - loss: 1.0787 - accuracy: 0.5021 - val_loss: 1.0790 - val_accuracy: 0.5029\n",
      "Epoch 21/50\n",
      "53600/53600 [==============================] - 4s 73us/sample - loss: 1.0783 - accuracy: 0.5006 - val_loss: 1.0780 - val_accuracy: 0.5022\n",
      "Epoch 22/50\n",
      "53600/53600 [==============================] - 4s 69us/sample - loss: 1.0774 - accuracy: 0.5013 - val_loss: 1.0792 - val_accuracy: 0.5018\n",
      "Epoch 23/50\n",
      "53600/53600 [==============================] - 4s 69us/sample - loss: 1.0781 - accuracy: 0.5014 - val_loss: 1.0807 - val_accuracy: 0.4957\n",
      "Epoch 24/50\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 1.0790 - accuracy: 0.5009 - val_loss: 1.0815 - val_accuracy: 0.4999\n",
      "Epoch 25/50\n",
      "53600/53600 [==============================] - 4s 68us/sample - loss: 1.0781 - accuracy: 0.5018 - val_loss: 1.0878 - val_accuracy: 0.4991\n",
      "Epoch 26/50\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0790 - accuracy: 0.5023 - val_loss: 1.0954 - val_accuracy: 0.4970\n",
      "Epoch 27/50\n",
      "53600/53600 [==============================] - 4s 70us/sample - loss: 1.0788 - accuracy: 0.5005 - val_loss: 1.0892 - val_accuracy: 0.5019\n",
      "Epoch 28/50\n",
      "53600/53600 [==============================] - 4s 79us/sample - loss: 1.0786 - accuracy: 0.4999 - val_loss: 1.0876 - val_accuracy: 0.5012 0s - loss: 1.0805 - \n",
      "Epoch 29/50\n",
      "53600/53600 [==============================] - 4s 73us/sample - loss: 1.0790 - accuracy: 0.4991 - val_loss: 1.0848 - val_accuracy: 0.4985\n",
      "Epoch 30/50\n",
      "53600/53600 [==============================] - 4s 71us/sample - loss: 1.0802 - accuracy: 0.5013 - val_loss: 1.0807 - val_accuracy: 0.5045\n",
      "Epoch 31/50\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0778 - accuracy: 0.5033 - val_loss: 1.0823 - val_accuracy: 0.5006: 1.0771 - accura\n",
      "Epoch 32/50\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0786 - accuracy: 0.5005 - val_loss: 1.0924 - val_accuracy: 0.4936\n",
      "Epoch 33/50\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0808 - accuracy: 0.5006 - val_loss: 1.0818 - val_accuracy: 0.4987\n",
      "Epoch 34/50\n",
      "53600/53600 [==============================] - 4s 73us/sample - loss: 1.0792 - accuracy: 0.5008 - val_loss: 1.1196 - val_accuracy: 0.4920\n",
      "Epoch 35/50\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0799 - accuracy: 0.5009 - val_loss: 1.0782 - val_accuracy: 0.5037\n",
      "Epoch 36/50\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0786 - accuracy: 0.4994 - val_loss: 1.0888 - val_accuracy: 0.4968\n",
      "Epoch 37/50\n",
      "53600/53600 [==============================] - 4s 72us/sample - loss: 1.0784 - accuracy: 0.5011 - val_loss: 1.0937 - val_accuracy: 0.5007\n",
      "Epoch 38/50\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 1.0819 - accuracy: 0.4996 - val_loss: 1.0885 - val_accuracy: 0.5001\n",
      "Epoch 39/50\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0816 - accuracy: 0.5006 - val_loss: 1.0829 - val_accuracy: 0.4989\n",
      "Epoch 40/50\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0789 - accuracy: 0.5017 - val_loss: 1.0881 - val_accuracy: 0.4995\n",
      "Epoch 41/50\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 1.0797 - accuracy: 0.4999 - val_loss: 1.0900 - val_accuracy: 0.4992\n",
      "Epoch 42/50\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 1.0841 - accuracy: 0.5005 - val_loss: 1.0858 - val_accuracy: 0.5055\n",
      "Epoch 43/50\n",
      "53600/53600 [==============================] - 4s 76us/sample - loss: 1.0819 - accuracy: 0.5003 - val_loss: 1.0902 - val_accuracy: 0.5026\n",
      "Epoch 44/50\n",
      "53600/53600 [==============================] - 4s 74us/sample - loss: 1.0833 - accuracy: 0.5010 - val_loss: 1.0931 - val_accuracy: 0.4999\n",
      "Epoch 45/50\n",
      "53600/53600 [==============================] - 4s 80us/sample - loss: 1.0842 - accuracy: 0.4999 - val_loss: 1.0868 - val_accuracy: 0.5020\n",
      "Epoch 46/50\n",
      "53600/53600 [==============================] - 4s 80us/sample - loss: 1.0840 - accuracy: 0.4991 - val_loss: 1.0809 - val_accuracy: 0.4961\n",
      "Epoch 47/50\n",
      "53600/53600 [==============================] - 4s 81us/sample - loss: 1.0830 - accuracy: 0.4985 - val_loss: 1.0924 - val_accuracy: 0.5026\n",
      "Epoch 48/50\n",
      "53600/53600 [==============================] - 4s 80us/sample - loss: 1.0850 - accuracy: 0.4999 - val_loss: 1.0894 - val_accuracy: 0.5030\n",
      "Epoch 49/50\n",
      "53600/53600 [==============================] - 4s 77us/sample - loss: 1.0862 - accuracy: 0.5005 - val_loss: 1.0867 - val_accuracy: 0.5010\n",
      "Epoch 50/50\n",
      "53600/53600 [==============================] - 4s 81us/sample - loss: 1.0830 - accuracy: 0.4987 - val_loss: 1.1002 - val_accuracy: 0.4997\n",
      "[3 0 0 ... 1 2 2]\n",
      "Neural Network Test accuracy 0.49663636363636365\n",
      "Results after config 1 of 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >method</th>        <th class=\"col_heading level0 col1\" >accuracy</th>        <th class=\"col_heading level0 col2\" >predictions</th>        <th class=\"col_heading level0 col3\" >model</th>        <th class=\"col_heading level0 col4\" >config</th>        <th class=\"col_heading level0 col5\" >classes</th>        <th class=\"col_heading level0 col6\" >n_vars</th>        <th class=\"col_heading level0 col7\" >n</th>        <th class=\"col_heading level0 col8\" >max_mu</th>        <th class=\"col_heading level0 col9\" >max_sigma</th>        <th class=\"col_heading level0 col10\" >max_skew</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row0\" class=\"row_heading level0 row0\" >11</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col0\" class=\"data row0 col0\" >Net 50-50-50-50 E50</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col1\" class=\"data row0 col1\" >49.664%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col2\" class=\"data row0 col2\" >[3 0 0 ... 1 2 2]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col3\" class=\"data row0 col3\" ><tensorflow.python.keras.engine.training.Model object at 0x000002D98C693E80></td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col4\" class=\"data row0 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col5\" class=\"data row0 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col6\" class=\"data row0 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col7\" class=\"data row0 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col8\" class=\"data row0 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col9\" class=\"data row0 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row0_col10\" class=\"data row0 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col0\" class=\"data row1 col0\" >Net 30-30-30-30 E10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col1\" class=\"data row1 col1\" >49.658%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col2\" class=\"data row1 col2\" >[3 0 0 ... 1 2 1]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col3\" class=\"data row1 col3\" ><tensorflow.python.keras.engine.training.Model object at 0x000002D982AB89B0></td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col4\" class=\"data row1 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col5\" class=\"data row1 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col6\" class=\"data row1 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col7\" class=\"data row1 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col8\" class=\"data row1 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col9\" class=\"data row1 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row1_col10\" class=\"data row1 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row2\" class=\"row_heading level0 row2\" >9</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col0\" class=\"data row2 col0\" >Net 4 E25</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col1\" class=\"data row2 col1\" >49.218%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col2\" class=\"data row2 col2\" >[3 0 0 ... 1 2 2]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col3\" class=\"data row2 col3\" ><tensorflow.python.keras.engine.training.Model object at 0x000002D8B66470B8></td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col4\" class=\"data row2 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col5\" class=\"data row2 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col6\" class=\"data row2 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col7\" class=\"data row2 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col8\" class=\"data row2 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col9\" class=\"data row2 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row2_col10\" class=\"data row2 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col0\" class=\"data row3 col0\" >KNN-100</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col1\" class=\"data row3 col1\" >47.564%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col2\" class=\"data row3 col2\" >[3. 0. 0. ... 1. 2. 1.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col3\" class=\"data row3 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=100, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col4\" class=\"data row3 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col5\" class=\"data row3 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col6\" class=\"data row3 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col7\" class=\"data row3 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col8\" class=\"data row3 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col9\" class=\"data row3 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col0\" class=\"data row4 col0\" >KNN-50</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col1\" class=\"data row4 col1\" >47.091%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col2\" class=\"data row4 col2\" >[3. 0. 0. ... 1. 3. 2.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col3\" class=\"data row4 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=50, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col4\" class=\"data row4 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col5\" class=\"data row4 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col6\" class=\"data row4 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col7\" class=\"data row4 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col8\" class=\"data row4 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col9\" class=\"data row4 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row4_col10\" class=\"data row4 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row5\" class=\"row_heading level0 row5\" >0</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col0\" class=\"data row5 col0\" >LDA</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col1\" class=\"data row5 col1\" >46.742%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col2\" class=\"data row5 col2\" >[3. 0. 0. ... 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col3\" class=\"data row5 col3\" >LinearDiscriminantAnalysis(n_components=None, priors=[0.25, 0.25, 0.25, 0.25],\n",
       "              shrinkage=None, solver='svd', store_covariance=False,\n",
       "              tol=0.0001)</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col4\" class=\"data row5 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col5\" class=\"data row5 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col6\" class=\"data row5 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col7\" class=\"data row5 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col8\" class=\"data row5 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col9\" class=\"data row5 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row5_col10\" class=\"data row5 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row6\" class=\"row_heading level0 row6\" >2</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col0\" class=\"data row6 col0\" >Logit</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col1\" class=\"data row6 col1\" >46.736%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col2\" class=\"data row6 col2\" >[3. 0. 0. ... 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col3\" class=\"data row6 col3\" >LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col4\" class=\"data row6 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col5\" class=\"data row6 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col6\" class=\"data row6 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col7\" class=\"data row6 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col8\" class=\"data row6 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col9\" class=\"data row6 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row6_col10\" class=\"data row6 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col0\" class=\"data row7 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col1\" class=\"data row7 col1\" >46.612%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col2\" class=\"data row7 col2\" >[3. 0. 0. ... 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col3\" class=\"data row7 col3\" >GaussianNB(priors=[0.25, 0.25, 0.25, 0.25], var_smoothing=1e-09)</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col4\" class=\"data row7 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col5\" class=\"data row7 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col6\" class=\"data row7 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col7\" class=\"data row7 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col8\" class=\"data row7 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col9\" class=\"data row7 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row7_col10\" class=\"data row7 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row8\" class=\"row_heading level0 row8\" >1</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col0\" class=\"data row8 col0\" >QDA</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col1\" class=\"data row8 col1\" >46.561%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col2\" class=\"data row8 col2\" >[3. 0. 0. ... 1. 2. 2.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col3\" class=\"data row8 col3\" >QuadraticDiscriminantAnalysis(priors=array([0.25, 0.25, 0.25, 0.25]),\n",
       "               reg_param=0.0, store_covariance=False,\n",
       "               store_covariances=None, tol=0.0001)</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col4\" class=\"data row8 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col5\" class=\"data row8 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col6\" class=\"data row8 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col7\" class=\"data row8 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col8\" class=\"data row8 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col9\" class=\"data row8 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row8_col10\" class=\"data row8 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row9\" class=\"row_heading level0 row9\" >8</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col0\" class=\"data row9 col0\" >SVM</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col1\" class=\"data row9 col1\" >45.567%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col2\" class=\"data row9 col2\" >[3. 0. 0. ... 1. 0. 2.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col3\" class=\"data row9 col3\" >LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col4\" class=\"data row9 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col5\" class=\"data row9 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col6\" class=\"data row9 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col7\" class=\"data row9 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col8\" class=\"data row9 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col9\" class=\"data row9 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row9_col10\" class=\"data row9 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row10\" class=\"row_heading level0 row10\" >4</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col0\" class=\"data row10 col0\" >KNN-10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col1\" class=\"data row10 col1\" >44.967%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col2\" class=\"data row10 col2\" >[3. 0. 2. ... 3. 2. 3.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col3\" class=\"data row10 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col4\" class=\"data row10 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col5\" class=\"data row10 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col6\" class=\"data row10 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col7\" class=\"data row10 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col8\" class=\"data row10 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col9\" class=\"data row10 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row10_col10\" class=\"data row10 col10\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098level0_row11\" class=\"row_heading level0 row11\" >3</th>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col0\" class=\"data row11 col0\" >KNN-5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col1\" class=\"data row11 col1\" >42.697%</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col2\" class=\"data row11 col2\" >[0. 0. 0. ... 2. 2. 1.]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col3\" class=\"data row11 col3\" >KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col4\" class=\"data row11 col4\" >7</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col5\" class=\"data row11 col5\" >[0.25, 0.25, 0.25, 0.25]</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col6\" class=\"data row11 col6\" >5</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col7\" class=\"data row11 col7\" >100000</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col8\" class=\"data row11 col8\" >1</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col9\" class=\"data row11 col9\" >10</td>\n",
       "                        <td id=\"T_e9b8187a_15d7_11ea_98f2_9cb6d0e5d098row11_col10\" class=\"data row11 col10\" >10</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d8b6652240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "timelabel =  datetime.now().strftime(\"%H-%M-%S - %d-%m-%Y\")\n",
    "\n",
    "\n",
    "configs = [{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 500,\n",
    "    \"max_mu\": 2,\n",
    "    \"max_sigma\": 2,\n",
    "    \"max_skew\": 1\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 5,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.05, 0.05, 0.05, 0.85],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 5,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 50,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 5,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 10000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.125 for x in range(8)],\n",
    "    \"n_vars\": 5,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 1000000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 5,\n",
    "    \"max_skew\": 5\n",
    "}]\n",
    "\n",
    "\n",
    "\n",
    "columns = ['method', 'accuracy','predictions', \"model\", \"config\"] + list(configs[0].keys())\n",
    "results = pd.DataFrame(columns=columns)\n",
    "results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "#run analysis\n",
    "for i, c in enumerate(configs):\n",
    "    X_train, X_test, y_train, y_test = simulate_data(c[\"classes\"], c[\"n_vars\"], c[\"n\"], c[\"max_mu\"], c[\"max_sigma\"], c[\"max_skew\"])\n",
    "    \n",
    "    c_n = 7\n",
    "    \n",
    "    lda = classify_lda(X_train, X_test, y_train, y_test, c[\"classes\"], False)                                     \n",
    "    results = results.append({**lda, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    qda = classify_qda(X_train, X_test, y_train, y_test, c[\"classes\"])                                     \n",
    "    results = results.append({**qda, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    logit = classify_logit(X_train, X_test, y_train, y_test)                                     \n",
    "    results = results.append({**logit, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    for k in [5,10,50,100]:\n",
    "        knn = classify_knn(X_train, X_test, y_train, y_test, k)\n",
    "        results = results.append({**knn, **c, \"config\":c_n},ignore_index=True)\n",
    "\n",
    "    bayes = classify_naivebayes(X_train, X_test, y_train, y_test, c[\"classes\"])\n",
    "    results = results.append({**bayes, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    svm = classify_svm(X_train, X_test, y_train, y_test)\n",
    "    results = results.append({**svm, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    for n in [{\"d\":1,\"n\":len(c[\"classes\"]), \"e\":25}, {\"d\":4,\"n\":30, \"e\":10}, {\"d\":4,\"n\":50, \"e\":50}]:\n",
    "        neuralnet = classify_neuralnet(X_train, X_test, y_train, y_test, c[\"n_vars\"], len(c[\"classes\"]),  depth=n[\"d\"], nodes=n[\"n\"], epochs=n[\"e\"])                                 \n",
    "        results = results.append({**neuralnet, **c, \"config\":c_n},ignore_index=True)\n",
    "    \n",
    "    print(\"Results after config \"+str(i+1)+\" of \"+str(len(configs)))\n",
    "\n",
    "    results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "        \n",
    "    display(results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "    }))\n",
    "    \n",
    "\n",
    "    #saving results to file\n",
    "    results.drop(columns=['model']).to_pickle(\"./results/config \"+str(i+1)+\" of \"+str(len(configs))+\" \"+timelabel+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example to load old results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e1a387718ede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch1' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def bold(data):\n",
    "    attr = 'font-weight: {}'.format(\"700\")\n",
    "    #remove % and cast to float\n",
    "    data = data.replace('%','', regex=True).astype(float)\n",
    "    is_max = data == data.max()\n",
    "    return [attr if v else \"\" for v in is_max]\n",
    "    \n",
    "def boldlatex(data):\n",
    "    #remove % and cast to float\n",
    "    return list(map(lambda x: r\"\\\\textbf{\"+x+\"}\" if x==data.max() else x, data))\n",
    "\n",
    "# configs = [{\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 2,\n",
    "#     \"n\": 500,\n",
    "#     \"max_mu\": 2,\n",
    "#     \"max_sigma\": 2,\n",
    "#     \"max_skew\": 1\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.05, 0.05, 0.05, 0.85],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 50,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 50,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# }\n",
    "# configs = [{\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 2,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.125 for x in range(8)],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# }] \n",
    "\n",
    "# configs = [{\n",
    "#     \"classes\": [0.5, 0.5],\n",
    "#     \"n_vars\": 2,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.5, 0.5],\n",
    "#     \"n_vars\": 2,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.5, 0.5],\n",
    "#     \"n_vars\": 2,\n",
    "#     \"n\": 1000000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# }\n",
    "# ]\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "old_results = pd.read_pickle(\"./results/config 7 of 7 21-02-19 - 02-12-2019.pkl\")\n",
    "\n",
    "\n",
    "# .style.format({'accuracy': '{:,.3%}'.format})\n",
    "\n",
    "\n",
    "\n",
    "table = pd.concat([batch1])\n",
    "table['accuracy'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in table['accuracy']], index = table.index)\n",
    "table = table.pivot(index='method', columns='config', values='accuracy').sort_values(by='method')\n",
    "display(table.style.apply(bold))\n",
    "latex = table.apply(boldlatex).to_latex()\n",
    "print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
