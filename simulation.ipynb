{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate PythonGPU\n",
    "import numpy as np\n",
    "from scipy.stats import skewnorm, skew\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, accuracy_score\n",
    "\n",
    "def simulate_data(classes, n_vars, n, max_mu, max_sigma, max_skew):\n",
    "    #The multivariate skew normal number generator\n",
    "    def rng(mu, sigma, skew, n=1):\n",
    "        k = len(mu)\n",
    "        if not (k == len(sigma) and k ==len(skew)): \n",
    "            raise Exception(\"Mu, Sigma and Skew should be same length\")\n",
    "\n",
    "        data = np.zeros((int(n),k))\n",
    "\n",
    "        for i in range(k):\n",
    "            data[:,i] = skewnorm.rvs(skew[i], loc=mu[i], scale=sigma[i], size=int(n)) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    if(np.sum(classes) != 1):\n",
    "        raise Exception(\"Classes dont sum up to 1\")\n",
    "        \n",
    "    n_classes = len(classes)\n",
    "    sigma = np.random.randint(1,max_sigma,n_vars)\n",
    "    skew = np.random.randint(-max_skew,max_skew,n_vars)\n",
    "    mu =  np.random.randint(-max_mu, max_mu, (n_classes, n_vars))\n",
    "    \n",
    "    n_obs_class = np.round(np.dot(classes,n))\n",
    "    \n",
    "    data = np.zeros((int(np.sum(n_obs_class)),n_vars+1))\n",
    "    for i in range(n_classes):\n",
    "        #calculate indexes\n",
    "        start = int(np.sum(n_obs_class[0:i]))\n",
    "        end = int(np.sum(n_obs_class[0:i+1]))\n",
    "        \n",
    "        #set the data\n",
    "        data[start:end,0] = i\n",
    "        data[start:end,1:] = rng(mu[i,:], sigma, skew, n_obs_class[i])\n",
    "        \n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "    \n",
    "#     columns = [\"x\"+str(x) for x in range(n_vars + 1)]\n",
    "#     columns[0] = \"class\"\n",
    "    \n",
    "#     df = pd.DataFrame(data,columns=columns)\n",
    "#     df[\"class\"] = df[\"class\"].astype(int)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def classify_lda(X_train, X_test, y_train, y_test, priors, plot=False):\n",
    "    lda = LinearDiscriminantAnalysis(priors=priors)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    predictions = lda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"LDA Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    report = classification_report(y_test, predictions)\n",
    "    print(report)\n",
    "\n",
    "    if plot:    \n",
    "        plt.xlabel('LD1')\n",
    "        plt.ylabel('LD2')\n",
    "        plt.scatter(\n",
    "            X_lda[:,0],\n",
    "            X_lda[:,1],\n",
    "            c=y_train,\n",
    "            cmap='Accent',\n",
    "        )\n",
    "        \n",
    "    return {\"method\": \"LDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"report\": report,\n",
    "            \"model\": lda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadratic\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify_qda(X_train, X_test, y_train, y_test, priors):\n",
    "    qda = QuadraticDiscriminantAnalysis(priors=priors)\n",
    "    X_qda = qda.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = qda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"QDA Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    report = classification_report(y_test, predictions)\n",
    "    print(report)\n",
    "\n",
    "    return {\"method\": \"QDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"report\": report,\n",
    "            \"model\": qda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classify_logit(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                             multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Logistic Test accuracy \"+ str(accuracy))\n",
    "\n",
    "    report = classification_report(y_test, predictions)\n",
    "    print(report)\n",
    "    \n",
    "    return {\"method\": \"Logit\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"report\": report,\n",
    "            \"model\": clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "def classify_neuralnet(X_train, X_test, y_train, y_test, n_vars, depth=1, nodes=10, epochs=20):\n",
    "    inputs = keras.Input(shape=(n_vars,), name='obs')\n",
    "    x = layers.Dense(nodes, activation='relu')(inputs)\n",
    "    \n",
    "    if(depth>1):\n",
    "        for i in range(depth-1):\n",
    "            x = layers.Dense(nodes, activation='relu')(x)\n",
    "            \n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='Dataset')\n",
    "\n",
    "    display(model.summary())\n",
    "\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=64,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2)\n",
    "\n",
    "    predictions = model.predict(X_test, y_test, verbose=2)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Neural Network Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    report = classification_report(y_test, predictions)\n",
    "    print(report)\n",
    "    \n",
    "    return {\"method\": \"Neural Net\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"report\": report,\n",
    "            \"model\": model}\n",
    "\n",
    "\n",
    "# print('Test loss:', test_scores[0])\n",
    "# print('Test accuracy:', test_scores[1])\n",
    "\n",
    "# accuracies = accuracies.append({\"method\": \"Neural Net\", \n",
    "#                    \"accuracy\": test_scores[1], \n",
    "#                    \"predictions\":clf_pred}, \n",
    "#                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test accuracy 0.5007272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.32      0.35      8250\n",
      "         1.0       0.89      0.86      0.87      8250\n",
      "         2.0       0.37      0.56      0.44      8250\n",
      "         3.0       0.39      0.28      0.32      8250\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     33000\n",
      "   macro avg       0.51      0.50      0.50     33000\n",
      "weighted avg       0.51      0.50      0.50     33000\n",
      "\n",
      "QDA Test accuracy 0.5025151515151515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.21      0.28      8250\n",
      "         1.0       0.89      0.86      0.87      8250\n",
      "         2.0       0.37      0.55      0.44      8250\n",
      "         3.0       0.38      0.39      0.39      8250\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     33000\n",
      "   macro avg       0.51      0.50      0.49     33000\n",
      "weighted avg       0.51      0.50      0.49     33000\n",
      "\n",
      "Logistic Test accuracy 0.49542424242424243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.30      0.34      8250\n",
      "         1.0       0.86      0.87      0.86      8250\n",
      "         2.0       0.36      0.52      0.43      8250\n",
      "         3.0       0.39      0.29      0.33      8250\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     33000\n",
      "   macro avg       0.50      0.50      0.49     33000\n",
      "weighted avg       0.50      0.50      0.49     33000\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'module' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-0994fa1057ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mneuralnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify_neuralnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_vars\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mneuralnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-da7d41ac9e22>\u001b[0m in \u001b[0;36mclassify_neuralnet\u001b[1;34m(X_train, X_test, y_train, y_test, n_vars, depth, nodes, epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'module' and 'int'"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "configs = [{\n",
    "    \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 4,\n",
    "    \"max_sigma\": 30,\n",
    "    \"max_skew\": 10\n",
    "}] \n",
    "\n",
    "columns = ['method', 'accuracy','predictions', \"report\", \"model\", \"config\"] + list(configs[0].keys())\n",
    "results = pd.DataFrame(columns=columns)\n",
    "\n",
    "#run analysis\n",
    "for i, c in enumerate(configs):\n",
    "    X_train, X_test, y_train, y_test = simulate_data(c[\"classes\"], c[\"n_vars\"], c[\"n\"], c[\"max_mu\"], c[\"max_sigma\"], c[\"max_skew\"])\n",
    "    \n",
    "    lda = classify_lda(X_train, X_test, y_train, y_test, c[\"classes\"], False)                                     \n",
    "    results = results.append({**lda, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    qda = classify_qda(X_train, X_test, y_train, y_test, c[\"classes\"])                                     \n",
    "    results = results.append({**qda, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    logit = classify_logit(X_train, X_test, y_train, y_test)                                     \n",
    "    results = results.append({**logit, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    neuralnet = classify_neuralnet(X_train, X_test, y_train, y_test, c[\"n_vars\"], depth=2, nodes=20, epochs=5)                                 \n",
    "    results = results.append({**neuralnet, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    print(\"Results after config \"+str(i+1))\n",
    "    display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
