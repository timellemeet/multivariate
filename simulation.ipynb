{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate PythonGPU\n",
    "import numpy as np\n",
    "from scipy.stats import skewnorm, skew\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, accuracy_score\n",
    "\n",
    "def simulate_data(classes, n_vars, n, max_mu, max_sigma, max_skew):\n",
    "    #The multivariate skew normal number generator\n",
    "    def rng(mu, sigma, skew, n=1):\n",
    "        k = len(mu)\n",
    "        if not (k == len(sigma) and k ==len(skew)): \n",
    "            raise Exception(\"Mu, Sigma and Skew should be same length\")\n",
    "\n",
    "        data = np.zeros((int(n),k))\n",
    "\n",
    "        for i in range(k):\n",
    "            data[:,i] = skewnorm.rvs(skew[i], loc=mu[i], scale=sigma[i], size=int(n)) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    if(np.sum(classes) != 1):\n",
    "        raise Exception(\"Classes dont sum up to 1\")\n",
    "        \n",
    "    n_classes = len(classes)\n",
    "#     sigma = np.random.randint(1,max_sigma,n_vars)\n",
    "#     skew = np.random.randint(-max_skew,max_skew,n_vars)\n",
    "#     mu =  np.random.randint(-max_mu, max_mu, (n_classes, n_vars))\n",
    "    \n",
    "    sigma = (max_sigma * np.random.rand(1,n_vars))[0]\n",
    "    skew = ((2 * max_skew  * np.random.rand(1, n_vars)) - max_skew)[0]\n",
    "    mu = (2 *  max_mu * np.random.rand(n_classes, n_vars)) - max_mu\n",
    "    \n",
    "    n_obs_class = np.round(np.dot(classes,n))\n",
    "    \n",
    "    data = np.zeros((int(np.sum(n_obs_class)),n_vars+1))\n",
    "    for i in range(n_classes):\n",
    "        #calculate indexes\n",
    "        start = int(np.sum(n_obs_class[0:i]))\n",
    "        end = int(np.sum(n_obs_class[0:i+1]))\n",
    "        \n",
    "        #set the data\n",
    "        data[start:end,0] = i\n",
    "        data[start:end,1:] = rng(mu[i,:], sigma, skew, n_obs_class[i])\n",
    "        \n",
    "    X = data[:,1:]\n",
    "    y = data[:,0]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def classify_lda(X_train, X_test, y_train, y_test, priors, plot=False):\n",
    "    lda = LinearDiscriminantAnalysis(priors=priors)\n",
    "    X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "    predictions = lda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"LDA Test accuracy \"+ str(accuracy))\n",
    "    print(predictions)\n",
    "\n",
    "    if plot:    \n",
    "        plt.xlabel('LD1')\n",
    "        plt.ylabel('LD2')\n",
    "        plt.scatter(\n",
    "            X_lda[:,0],\n",
    "            X_lda[:,1],\n",
    "            c=y_train,\n",
    "            cmap='Accent',\n",
    "        )\n",
    "        \n",
    "    return {\"method\": \"LDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": lda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadratic\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify_qda(X_train, X_test, y_train, y_test, priors):\n",
    "    qda = QuadraticDiscriminantAnalysis(priors=priors)\n",
    "    X_qda = qda.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = qda.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"QDA Test accuracy \"+ str(accuracy))\n",
    "\n",
    "    return {\"method\": \"QDA\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": qda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classify_logit(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                             multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Logistic Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Logit\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def classify_knn(X_train, X_test, y_train, y_test, n_neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    predictions = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"KNN-\"+str(n_neighbors)+\" Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"KNN-\"+str(n_neighbors), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": knn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def classify_naivebayes(X_train, X_test, y_train, y_test, priors):\n",
    "    NB = GaussianNB(priors)\n",
    "    NB.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = NB.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"Naive Bayes Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Naive Bayes\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": NB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def classify_svm(X_train, X_test, y_train, y_test):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"SVM Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"SVM\", \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": svm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "def classify_neuralnet(X_train, X_test, y_train, y_test, n_vars, n_classes, depth=1, nodes=10, epochs=20):\n",
    "    inputs = keras.Input(shape=(n_vars,), name='obs')\n",
    "    x = layers.Dense(nodes, activation='relu')(inputs)\n",
    "    \n",
    "    if(depth>1):\n",
    "        for i in range(depth-1):\n",
    "            x = layers.Dense(nodes, activation='relu')(x)\n",
    "            \n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='Dataset')\n",
    "\n",
    "    display(model.summary())\n",
    "\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=64,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    print(predictions)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Neural Network Test accuracy \"+ str(accuracy))\n",
    "    \n",
    "    return {\"method\": \"Net \"+\"-\".join([str(nodes) for i in range(depth)])+ \" E\"+str(epochs), \n",
    "            \"accuracy\": accuracy, \n",
    "            \"predictions\":predictions,\n",
    "            \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test accuracy 0.29303030303030303\n",
      "[3. 3. 3. ... 1. 3. 0.]\n",
      "QDA Test accuracy 0.2923030303030303\n",
      "Logistic Test accuracy 0.29278787878787876\n",
      "KNN-5 Test accuracy 0.2674848484848485\n",
      "KNN-10 Test accuracy 0.2723939393939394\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "timelabel =  datetime.now().strftime(\"%H-%M-%S - %d-%m-%Y\")\n",
    "\n",
    "\n",
    "# configs = [{\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 2,\n",
    "#     \"n\": 500,\n",
    "#     \"max_mu\": 2,\n",
    "#     \"max_sigma\": 2,\n",
    "#     \"max_skew\": 1\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.05, 0.05, 0.05, 0.85],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 50,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 50,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 5,\n",
    "#     \"max_sigma\": 5,\n",
    "#     \"max_skew\": 5\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 10000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# }\n",
    "# configs = [{\n",
    "#     \"classes\": [0.25, 0.25, 0.25, 0.25],\n",
    "#     \"n_vars\": 2,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# },\n",
    "# {\n",
    "#     \"classes\": [0.125 for x in range(8)],\n",
    "#     \"n_vars\": 5,\n",
    "#     \"n\": 100000,\n",
    "#     \"max_mu\": 1,\n",
    "#     \"max_sigma\": 10,\n",
    "#     \"max_skew\": 10\n",
    "# }] \n",
    "\n",
    "configs = [{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 10\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 100000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 5\n",
    "},\n",
    "{\n",
    "    \"classes\": [0.5, 0.5],\n",
    "    \"n_vars\": 2,\n",
    "    \"n\": 1000000,\n",
    "    \"max_mu\": 1,\n",
    "    \"max_sigma\": 10,\n",
    "    \"max_skew\": 5\n",
    "}\n",
    "] \n",
    "\n",
    "\n",
    "columns = ['method', 'accuracy','predictions', \"model\", \"config\"] + list(configs[0].keys())\n",
    "results = pd.DataFrame(columns=columns)\n",
    "results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "#run analysis\n",
    "for i, c in enumerate(configs):\n",
    "    X_train, X_test, y_train, y_test = simulate_data(c[\"classes\"], c[\"n_vars\"], c[\"n\"], c[\"max_mu\"], c[\"max_sigma\"], c[\"max_skew\"])\n",
    "    \n",
    "    lda = classify_lda(X_train, X_test, y_train, y_test, c[\"classes\"], False)                                     \n",
    "    results = results.append({**lda, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    qda = classify_qda(X_train, X_test, y_train, y_test, c[\"classes\"])                                     \n",
    "    results = results.append({**qda, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    logit = classify_logit(X_train, X_test, y_train, y_test)                                     \n",
    "    results = results.append({**logit, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    for k in [5,10,50,100]:\n",
    "        knn = classify_knn(X_train, X_test, y_train, y_test, k)\n",
    "        results = results.append({**knn, **c, \"config\":i+1},ignore_index=True)\n",
    "\n",
    "    bayes = classify_naivebayes(X_train, X_test, y_train, y_test, c[\"classes\"])\n",
    "    results = results.append({**bayes, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    svm = classify_svm(X_train, X_test, y_train, y_test)\n",
    "    results = results.append({**svm, **c, \"config\":i+1},ignore_index=True)\n",
    "    \n",
    "    for n in [{\"d\":1,\"n\":len(c[\"classes\"]), \"e\":25}, {\"d\":4,\"n\":30, \"e\":10}, {\"d\":4,\"n\":50, \"e\":50}]:\n",
    "        neuralnet = classify_neuralnet(X_train, X_test, y_train, y_test, c[\"n_vars\"], len(c[\"classes\"]),  depth=n[\"d\"], nodes=n[\"n\"], epochs=n[\"e\"])                                 \n",
    "        results = results.append({**neuralnet, **c, \"config\":i+1+7+2},ignore_index=True)\n",
    "    \n",
    "    print(\"Results after config \"+str(i+1)+\" of \"+str(len(configs)))\n",
    "\n",
    "    results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "        \n",
    "    display(results.style.format({\n",
    "    'accuracy': '{:,.3%}'.format\n",
    "    }))\n",
    "    \n",
    "\n",
    "    #saving results to file\n",
    "    results.drop(columns=['model']).to_pickle(\"./results/config \"+str(i+1)+\" of \"+str(len(configs))+\" \"+timelabel+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example to load old results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col2 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col0 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col2 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col5 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col2 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col6 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col1 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col2 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col4 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col0 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col3 {\n",
       "            font-weight:  700;\n",
       "        }    #T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col4 {\n",
       "            font-weight:  700;\n",
       "        }</style><table id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098\" ><thead>    <tr>        <th class=\"index_name level0\" >config</th>        <th class=\"col_heading level0 col0\" >1</th>        <th class=\"col_heading level0 col1\" >2</th>        <th class=\"col_heading level0 col2\" >3</th>        <th class=\"col_heading level0 col3\" >4</th>        <th class=\"col_heading level0 col4\" >5</th>        <th class=\"col_heading level0 col5\" >6</th>        <th class=\"col_heading level0 col6\" >7</th>    </tr>    <tr>        <th class=\"index_name level0\" >method</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row0\" class=\"row_heading level0 row0\" >KNN-10</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col0\" class=\"data row0 col0\" >49.09%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col1\" class=\"data row0 col1\" >94.88%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col2\" class=\"data row0 col2\" >99.24%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col3\" class=\"data row0 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col4\" class=\"data row0 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col5\" class=\"data row0 col5\" >38.85%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row0_col6\" class=\"data row0 col6\" >34.71%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row1\" class=\"row_heading level0 row1\" >KNN-100</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col0\" class=\"data row1 col0\" >47.27%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col1\" class=\"data row1 col1\" >92.36%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col2\" class=\"data row1 col2\" >98.64%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col3\" class=\"data row1 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col4\" class=\"data row1 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col5\" class=\"data row1 col5\" >42.27%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row1_col6\" class=\"data row1 col6\" >37.74%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row2\" class=\"row_heading level0 row2\" >KNN-5</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col0\" class=\"data row2 col0\" >44.85%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col1\" class=\"data row2 col1\" >95.12%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col2\" class=\"data row2 col2\" >99.36%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col3\" class=\"data row2 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col4\" class=\"data row2 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col5\" class=\"data row2 col5\" >35.73%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row2_col6\" class=\"data row2 col6\" >33.19%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row3\" class=\"row_heading level0 row3\" >KNN-50</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col0\" class=\"data row3 col0\" >53.94%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col1\" class=\"data row3 col1\" >93.45%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col2\" class=\"data row3 col2\" >98.88%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col3\" class=\"data row3 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col4\" class=\"data row3 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col5\" class=\"data row3 col5\" >41.03%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row3_col6\" class=\"data row3 col6\" >37.41%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row4\" class=\"row_heading level0 row4\" >LDA</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col0\" class=\"data row4 col0\" >55.76%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col1\" class=\"data row4 col1\" >96.82%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col2\" class=\"data row4 col2\" >99.97%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col3\" class=\"data row4 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col4\" class=\"data row4 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col5\" class=\"data row4 col5\" >45.24%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row4_col6\" class=\"data row4 col6\" >39.94%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row5\" class=\"row_heading level0 row5\" >Logit</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col0\" class=\"data row5 col0\" >56.36%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col1\" class=\"data row5 col1\" >96.82%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col2\" class=\"data row5 col2\" >99.88%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col3\" class=\"data row5 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col4\" class=\"data row5 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col5\" class=\"data row5 col5\" >45.67%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row5_col6\" class=\"data row5 col6\" >40.03%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row6\" class=\"row_heading level0 row6\" >Naive Bayes</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col0\" class=\"data row6 col0\" >53.33%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col1\" class=\"data row6 col1\" >96.85%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col2\" class=\"data row6 col2\" >99.97%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col3\" class=\"data row6 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col4\" class=\"data row6 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col5\" class=\"data row6 col5\" >45.06%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row6_col6\" class=\"data row6 col6\" >39.95%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row7\" class=\"row_heading level0 row7\" >Net 30-30-30-30 E10</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col0\" class=\"data row7 col0\" >52.12%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col1\" class=\"data row7 col1\" >96.36%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col2\" class=\"data row7 col2\" >99.70%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col3\" class=\"data row7 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col4\" class=\"data row7 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col5\" class=\"data row7 col5\" >45.85%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row7_col6\" class=\"data row7 col6\" >41.18%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row8\" class=\"row_heading level0 row8\" >Net 4 E25</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col0\" class=\"data row8 col0\" >33.94%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col1\" class=\"data row8 col1\" >95.52%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col2\" class=\"data row8 col2\" >99.24%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col3\" class=\"data row8 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col4\" class=\"data row8 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col5\" class=\"data row8 col5\" >44.73%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row8_col6\" class=\"data row8 col6\" >41.04%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row9\" class=\"row_heading level0 row9\" >Net 50-50-50-50 E50</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col0\" class=\"data row9 col0\" >52.12%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col1\" class=\"data row9 col1\" >96.15%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col2\" class=\"data row9 col2\" >99.97%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col3\" class=\"data row9 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col4\" class=\"data row9 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col5\" class=\"data row9 col5\" >44.91%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row9_col6\" class=\"data row9 col6\" >41.23%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row10\" class=\"row_heading level0 row10\" >QDA</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col0\" class=\"data row10 col0\" >52.73%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col1\" class=\"data row10 col1\" >96.97%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col2\" class=\"data row10 col2\" >99.97%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col3\" class=\"data row10 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col4\" class=\"data row10 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col5\" class=\"data row10 col5\" >45.21%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row10_col6\" class=\"data row10 col6\" >40.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098level0_row11\" class=\"row_heading level0 row11\" >SVM</th>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col0\" class=\"data row11 col0\" >56.36%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col1\" class=\"data row11 col1\" >95.36%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col2\" class=\"data row11 col2\" >99.48%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col3\" class=\"data row11 col3\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col4\" class=\"data row11 col4\" >100.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col5\" class=\"data row11 col5\" >43.00%</td>\n",
       "                        <td id=\"T_29893026_1550_11ea_aa17_9cb6d0e5d098row11_col6\" class=\"data row11 col6\" >38.23%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20b3396fe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "config &                 1 &                 2 &                 3 &                  4 &                  5 &                 6 &                 7 \\\\\n",
      "method              &                   &                   &                   &                    &                    &                   &                   \\\\\n",
      "\\midrule\n",
      "KNN-10              &            49.09\\% &            94.88\\% &            99.24\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            38.85\\% &            34.71\\% \\\\\n",
      "KNN-100             &            47.27\\% &            92.36\\% &            98.64\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            42.27\\% &            37.74\\% \\\\\n",
      "KNN-5               &            44.85\\% &            95.12\\% &            99.36\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            35.73\\% &            33.19\\% \\\\\n",
      "KNN-50              &            53.94\\% &            93.45\\% &            98.88\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            41.03\\% &            37.41\\% \\\\\n",
      "LDA                 &            55.76\\% &            96.82\\% &  \\textbackslash \\textbackslash textbf\\{99.97\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            45.24\\% &            39.94\\% \\\\\n",
      "Logit               &  \\textbackslash \\textbackslash textbf\\{56.36\\%\\} &            96.82\\% &            99.88\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            45.67\\% &            40.03\\% \\\\\n",
      "Naive Bayes         &            53.33\\% &            96.85\\% &  \\textbackslash \\textbackslash textbf\\{99.97\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            45.06\\% &            39.95\\% \\\\\n",
      "Net 30-30-30-30 E10 &            52.12\\% &            96.36\\% &            99.70\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{45.85\\%\\} &            41.18\\% \\\\\n",
      "Net 4 E25           &            33.94\\% &            95.52\\% &            99.24\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            44.73\\% &            41.04\\% \\\\\n",
      "Net 50-50-50-50 E50 &            52.12\\% &            96.15\\% &  \\textbackslash \\textbackslash textbf\\{99.97\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            44.91\\% &  \\textbackslash \\textbackslash textbf\\{41.23\\%\\} \\\\\n",
      "QDA                 &            52.73\\% &  \\textbackslash \\textbackslash textbf\\{96.97\\%\\} &  \\textbackslash \\textbackslash textbf\\{99.97\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            45.21\\% &            40.00\\% \\\\\n",
      "SVM                 &  \\textbackslash \\textbackslash textbf\\{56.36\\%\\} &            95.36\\% &            99.48\\% &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &  \\textbackslash \\textbackslash textbf\\{100.00\\%\\} &            43.00\\% &            38.23\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old_results = pd.read_pickle(\"./results/config 7 of 7 21-02-19 - 02-12-2019.pkl\")\n",
    "\n",
    "\n",
    "# .style.format({'accuracy': '{:,.3%}'.format})\n",
    "\n",
    "old_results['accuracy'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in old_results['accuracy']], index = old_results.index)\n",
    "\n",
    "\n",
    "def bold(data):\n",
    "    attr = 'font-weight: {}'.format(\"700\")\n",
    "    #remove % and cast to float\n",
    "    data = data.replace('%','', regex=True).astype(float)\n",
    "    is_max = data == data.max()\n",
    "    return [attr if v else \"\" for v in is_max]\n",
    "    \n",
    "def boldlatex(data):\n",
    "    #remove % and cast to float\n",
    "    return list(map(lambda x: r\"\\\\textbf{\"+x+\"}\" if x==data.max() else x, data))\n",
    "    \n",
    "#     return [attr if v else \"\" for v in is_max]\n",
    "    \n",
    "    \n",
    "table = old_results.pivot(index='method', columns='config', values='accuracy').sort_values(by='method')\n",
    "\n",
    "display(table.style.apply(bold))\n",
    "\n",
    "\n",
    "latex = table.apply(boldlatex).to_latex()\n",
    "print(latex)\n",
    "\n",
    "file = open(\"results.tex\", \"w\")\n",
    "file.write(latex)\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
